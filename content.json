{"meta":{"title":"禹哥小站","subtitle":"","description":"","author":"spartguo","url":"http://yoursite.com","root":"/"},"pages":[{"title":"Categories","date":"2019-11-07T08:52:01.000Z","updated":"2019-11-07T08:56:04.345Z","comments":false,"path":"Categories/index.html","permalink":"http://yoursite.com/Categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-11-07T07:33:35.000Z","updated":"2019-11-07T07:59:32.665Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"服务器-nginx配置","slug":"服务器-nginx配置","date":"2019-12-03T05:51:13.000Z","updated":"2019-12-04T14:02:45.673Z","comments":true,"path":"2019/12/03/服务器-nginx配置/","link":"","permalink":"http://yoursite.com/2019/12/03/%E6%9C%8D%E5%8A%A1%E5%99%A8-nginx%E9%85%8D%E7%BD%AE/","excerpt":"","text":"引言原来的服务器上的博客静态资源是通过nginx进行访问的，由于图片我之前是放在七牛云上面，但是访问图片的测试域名随时一个月就到期了，自己暂时也没有备案好的域名，所以希望说能够有个长期的落脚点，想着把图片也一起放到服务器的某个地方，然后通过特定的url通过nginx进行访问，但是在搞的过程中连配置文件都找了有一会儿，都不知道怎么搞。在此简单整理一波 nginx是啥百度百科如是说 Nginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，在BSD-like 协议下发行。其特点是占有内存少，并发能力强，事实上nginx的并发能力在同类型的网页服务器中表现较好。 提取关键点，就是个服务器，这玩意儿最大的特点就是有个代理机制。 正向代理 如上图，这个就是常见的一个模式，科学上网就是这么个运作模式，你访问google，但是有个墙挡住了，这个时候你就可以通过一个国外的，不会被墙挡住的服务器去访问，这个国外的服务器就充当了个代理的角色。服务器不知道谁要来访问我，我只需要知道有人来，我提供服务就好了。 而反向代理就是反过来，客户访问你，你有很多个服务，可能我图片放了一个地方，视频放了一个地方，这个时候你只需要发请求到代理服务器哪里，然后代理服务器nginx会自动解析url看看要发到哪里去，客户端不需要知道你发到哪里。 主要命令启动，左边那个其实就是sbin里面的，右边的是配置文件，我的配置文件在/etc/nginx里面 1nginx -c /usr/local/nginx/conf/nginx.conf 检查版本 1nginx -v 重新启动 1nginx -s reload 关于停止 正常停止或关闭Nginx 12nginx -s quit` 快速停止或关闭Nginx 1nginx -s stop 查看进程的方式 1ps -ef|grep nginx 从容停止 1kill -QUIT 进程号 快速停止 1kill -TERM 进程号 强制停止 1pkill -9 nginx 下面几个和最上面非查看进程的方式异曲同工 安装/删除安装安装没啥问题，直接用 1apt-get install nginx 删除在搞完某个配置的时候，想重启，结果有点问题，应该是配置上的问题，我个人比较懒，就想着直接删了重来，结果呵呵，遇到了写问题 痛苦根源一开始想着彻底卸载，直接调用 1sudo apt-get --purge remove nginx 然后网上删各种文件夹。 然后再装回来，看起来非常方便，很舒胡。 1sudo apt-get install install nginx 因为我要改里面的配置，所以打算搞个重启 1sudo service nginx restart 结果来一句 1job for nginx.service failed because the control process exited with error code. See “systemctl stat 更惨的是我删了重来，这个错误依然在 服务也一直开不起来 通过查阅资料主要是如下两个问题 配置文件有问题 已经启动nginx配置或者端口被占用 关于这个问题这篇文章对我有点小启发nginx启动报错 而且安装完了之后因为我删去的/usr/sbin/下的nginx文件，我输入 1nginx -v 上面提示我没有部分包，我也有点奇怪为啥重新安装没有把包重新安装了呢？ 因为有问题的时候瞎搞了很多步骤，时间比较紧，也就没有看到底出在哪，我的解决重点在怎么删干净，也没有截图，估计里面涉及到很多问题，导致现在部分东西没办法复现，所以后续再深入探讨。 对于上面的问题，我觉得这篇文章很有帮助 记一次重装nginx时遇到的问题 彻底删除经过一番查阅知道，原来彻底删除的正确姿势是这样的 删除nginx，包含配置文件 1sudo apt-get --purge remove nginx 自动移除全部不使用的软件包 1sudo apt-get autoremove 罗列出与nginx相关的软件 1dpkg --get-selections|grep nginx 可能会有nginx-common这些东西还留着，出现几个删几个，都删了，片甲不留 当然有个直接的方法，可以直接 1sudo apt-get --purge remove nginx* 查看nginx正在运行的进程，如果有就kill掉 1ps -ef |grep nginx 全局查找与nginx相关的文件，找到后就删掉 1sudo find / -name nginx* 找到文件一个个删有点累，可以来个组合命令。 1find / -name nginx* -exec rm -rf &#123;&#125; \\; 到了这一步差不多了。 主要配置这里只搞基本的东西 接下来看下配置总体情况 整体结构图 全局块该部分配置主要影响Nginx全局： 必须配置 指定运行worker进程的用户和组；user USERNAME [GROUPNAME]比如：user www-data; 指定nginx守护进程的pid文件pid /path/to/pid_file; 指定所有worker进程所能够打开的最大文件句柄数;worker_rlimit_nofile #; 性能优化相关的配置 worker进程的个数：通常应该略小于CPU物理核心数;worker_processes # 优点：提升缓存的命中率worker_cpu_affinity cpumask…;例子：worker_cpu_affinity 00000001 00000010 00000100; 计时器解析度：降低此值，可减少gettimeofday()系统调用的次数timer_resolution 指明worker进程的nice值worker_priority number; event块该部分配置主要影响Nginx服务器与用户的网络连接，主要包括： 基本配置 master调度用户请求至各worker进程时使用的负载均衡锁；on表示能让多个worker轮流的、序列化的去响应新请求;accept_mutex {off|on}; accept_mutex用到的锁文件路径;lock_file; 指明使用的事件模型：建议让Nginx自行选择;use [epoll|rtsig|select|poll]; 设定单个worker进程所能够处理的最大并发连接数量worker_connections #; 调试定位问题 是否以守护进程方式运行nginx, 调试时应该设置为offdaemon {on|off}; 是否以master/worker模型来运行nginx；调试时可以设置为offmaster_process {on|off}; error_log 位置 级别；若要使用debug级别，需要在编译nginx时使用–with-debug选项;error_log file | stderr | syslog:server=address[,parameter=value] | memory:size [debug | info | notice | warn | error | crit | alert | emerg]; 常用配置 worker_processes worker_connections worker_cpu_affinity worker_priority http块http {}: 由ngx_http_core_module模块所引入； 基本设置在这里有一些基本设置，因为细节暂时没有用到，到时候再说，可以先放默认的设置上来。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354http &#123; ## # Basic Settings ## sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; # server_tokens off; # server_names_hash_bucket_size 64; # server_name_in_redirect off; include /etc/nginx/mime.types; default_type application/octet-stream; ## # SSL Settings ## ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE ssl_prefer_server_ciphers on; ## # Logging Settings ## access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ## # Gzip Settings ## gzip on; gzip_disable \"msie6\"; # gzip_vary on; # gzip_proxied any; # gzip_comp_level 6; # gzip_buffers 16 8k; # gzip_http_version 1.1; # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; ## # Virtual Host Configs ## include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*;&#125; 有问题可以参考下面两篇 Nginx基本功能及其原理linux服务基础之nginx配置详解 server块这里就是重点的配置的地方了，第一个要找到配置文件，因为一开始我是很懵的，大家都在nginx.conf里面，我在ubuntu里面安装的nginx的server{}块没有在nginx.conf的配置文件里面，反而在/etc/nginx/sites-available里面的default里面。 然后就是一些配置，以为杂七杂八的东西很多，且很多东西需要一个具体场景可能才会需要到，所以这里就简单整理一些基本的 listenlisten指令有三种配置方法： 1、listen address[:port] [ default_server ] [ ssl ]; 2、listen port [ default_server ] [ ssl ]; 3、listen unix:path [ default_server ] [ ssl ]; 使用示例： listen *:80 | *:8000; ###监听所有80和8000端口 listen 192.168.1.10；###监听具体IP的所有端口上的连接 listen 8000；###监听具体端口上的所有IP连接，等同于listen *:8000; server_name设置虚拟主机名称。可以设置多个name语法：server_name name…;例如： server_name myserver.com www.myserver.com; 因为我是在我自己的服务器上定位静态资源，不是代理，所以直接 1server_name localhost 然后里面貌似还可以用正则。 root指定根目录路径。语法：root path; 示例： 123location /picture/ &#123; root /myspace/blog;&#125; 这个的意思是url是/picture开头的，直接到这里来，然后这个root指引客户到/myspace/blog/picture里面拿东西 这个东西也可以直接在server写。我的部分静态资源就是这么请求的。 error_page设置网站的错误页面，语法为：error_page code … [=[response]]uri; code：要处理的HTTP错误代码 response：将code指定的错误代码转换为新的错误代码 uri：错误页面的路径或者网站地址，这个uri是相对于root设置的根路径而言的。 示例： 1error_page 404 /404.html; allow基于IP的访问控制： 1allow address | CIDR | unix |all; 设置允许访问的IP范围 1deny address | CIDR | unix:| all; 12345location /t/ &#123; root /data/www/vhost2/; allow 172.16.100.120; deny all;&#125; 仅允许172.16.100.120这个IP地址访问 index入口可以解析的文件类型 栗子： 1index index.html index.php index.htm proxy_pass这个是在location块里面的，这个的意思是一旦有url和这个location匹配了，就直接把请求转到这个url里面去 1proxy_pass http://127.0.0.1:80; proxy_set_header这个是把客户端需要转发到后端服务器的头部一起转发过去 12proxy_set_header Host $host; proxy_set_header X-Forwarder-For $remote_addr; proxy_redirect这个功能很强大，当上游服务器返回的响应是重定向或刷新请求（如HTTP响应码是301或者302）时，proxy_redirect可以重设HTTP头部的location或refresh字段。 这个http头部的字段我不是很了解，简单查了下资料发现这个主要就是拿来跳转的。 而如果不写这个的话我们登录某个url-A，A转发给B，B发了个重定向给我们，就会在location头里面把B给带上，这样不太好，本来我就没办法访问B的或者本来B就不想让用户直接知道的，这样把B暴露了。 具体的操作可以是类似 1proxy_redirect B A 这样我们就可以啦，当然这只是一种情况，其他情况也有，具体可以参考下 Nginx反向代理中使用proxy_redirect重定向url 因为自己暂时也用不到那么多，所以暂时就整理自己需要的，后续有需要再继续更新。需要查找可以看这个Nginx基础入门之proxy反向代理常用配置项说明 如有问题，欢迎指正。 本文参考了Nginx可以做什么？看完这篇你就懂了Job for nginx.service failed because the control process exited with error code. See “systemctl statnginx启动失败问题集锦linux彻底删除nginxLinux下nginx 的常用命令Nginx基本功能及其原理linux服务基础之nginx配置详解Nginx关于server块和location块的配置当“服务器上部署多个Web应用”，使用Nginx反向代理配置","categories":[],"tags":[{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"数据库-jdbc总结","slug":"数据库-jdbc总结","date":"2019-11-21T11:51:39.000Z","updated":"2019-11-26T15:06:26.031Z","comments":true,"path":"2019/11/21/数据库-jdbc总结/","link":"","permalink":"http://yoursite.com/2019/11/21/%E6%95%B0%E6%8D%AE%E5%BA%93-jdbc%E6%80%BB%E7%BB%93/","excerpt":"","text":"引言本片文章参考自https://blog.csdn.net/jungle_rao/article/details/81274720https://www.cnblogs.com/javazs/p/7825316.html 介绍惯例，来段百度百科 Java数据库连接，（Java Database Connectivity，简称JDBC）是Java语言中用来规范客户端程序如何来访问数据库的应用程序接口，提供了诸如查询和更新数据库中数据的方法。 对于jdbc有如下图来解释比较好 jdbc 说白了jdbc其实是一个规范来的，规范了我java要操作数据库要怎么操作你都要给我个统一，对数据库的操作，你只需要关心如何操作JDBC API而不用考虑不同的数据库操作不同，或者部分字段类型不同。 而且人家做好了很多java的数据类型到数据库字段的类型的映射，比如String对应数据库的char和varchar。 举个栗子： 1select name from students where id = 2; 因为你是调用jdbc的java api的，本来name的类型是char，但是数据库的char和java的char不太一样，所以需要转，这个时候jdbc已经帮你转好了。 使用因为jdbc只是个规范，所以我们在操作不同的数据库要下载不同的jar包，里面有满足jdbc规范的针对某个特定数据库的驱动类。（ps：有时候也叫jdbc驱动，之前一直搞不清这些概念，233333） 这个驱动类实质上是实现了java.sql.Driver接口的一个类查看官网文档如下： Driver接口 担心凭借自己低分飘过的六级理解错，所以我谷歌翻译了一下 Modifier and Type Method and Description boolean acceptsURL(String url) 检索驱动程序是否认为它可以打开与给定URL的连接 Connection connect(String url, Properties info) 尝试建立到给定URL的数据库连接 int getMajorVersion( 检索驱动程序的主版本号。 int getMinorVersion() 获取驱动程序的次要版本号 Logger getParentLogger() 返回此驱动程序使用的所有Logger的父Logger。 DriverPropertyInfo[] getPropertyInfo(String url, Properties info) 获取有关此驱动程序可能的属性的信息。 boolean jdbcCompliant() 报告此驱动程序是否为正版JDBC Compliant™驱动程序 通过jdbc驱动和数据库操作的主要过程如下： 加载驱动首先要加载初始化驱动类，这个过程其实就是讲驱动类加载到我们的JVM里面。关于类加载过程可以到到这里看看 12//这里以Mysql为例Class.forName(\"com.mysql.jdbc.Driver\"); 为什么其他类我直接就可以搞，人家会自动触发加载，这个为啥要手动呢？因为这个加载过程中其实是为了运行里面的静态代码块来对驱动进行初始化的，至于为什么这样我也不深入了，只知道不这样会抛异常，后续有空再瞅一下。 建立连接我们在上面已经了解过有个接口叫connect(String url, Properties info)可以帮助我们连接到指定url的数据库。 使用Driver直接建立连接12345678//1.加载oracle驱动类，并实例化 Driver driver = (Driver) Class.forName(\"oracle.jdbc.driver.OracleDriver\").newInstance(); //2.创建真实的数据库连接： String url = \"jdbc:oracle:thin:@127.0.0.1:1521:xe\"; Properties props = new Properties(); props.put(\"user\", \"louluan\"); props.put(\"password\", \"123456\"); Connection connection = driver.connect(url, props); 在1和2之间我们也可以利用上面的测试接口，看看我们的url是否符合这个数据库的协议。然后再进行连接。 在连接过程中也发现了一个问题，就是这个连接单个数据库的时候没问题，但是连接多个数据库的时候我们就得搞多个Driver了，很麻烦。 DriverManager建立连接解决方式就是来个DriverManager，用来管理我们的Driver。这个东西挺厉害，所有的驱动类都被他管着，他也可以注册/注销Driver（这个细节可以看参考的第二篇博客），想怎么玩怎么玩，驱动类初期一加载初始化然后就会自动注册到DriverManager中让他管理。而且我们的某个数据库的Driver被注销了之后，重新通过DriverManger进行getDriver，就和没有进行初始化驱动类一个结果，抛异常。 这个DriverManager有个静态方法getDriver，可以通过传过来的URL，返回可以打开URL的Driver。(这个过程其实是DriverManager通过遍历每一个Driver的acceptsURL(url)判断这个url是符合哪一个的。 而为了更进一步的方便，有个getConnection 12Driver driver = DriverManager.getDriver(url); Connection connection = driver.connect(url, props); 也等价于 12Class.forName(\"oracle.jdbc.driver.OracleDriver\"); Connection connection = DriverManager.getConnection(url, props); 如果我们经常使用某个驱动，我们可以 12//设置值系统变量jdbc.drivers System.setProperty(\"jdbc.drivers\", \"oracle.jdbc.driver.OracleDriver\"); 这样，在DriverManager第一次使用的时候就会首先加载这个驱动类。因为DriverManager会在第一次加载的时候执行静态代码块初始化这个管理类 具体DriverManager的API可以看这里 通常我们我们也用这种方式 1Connection c = DriverManager.getConnection(\"jdbc:mysql://127.0.0.1:3306/exam?characterEncoding=UTF-8\", \"root\", \"admin\"); 执行SQL语句创建Statement这东西是也是一个接口类来的，它里面有很多函数我们可以通过connection的createStatement（）函数来获得statement对象。 Statement对象创建之后，可以执行SQL语句，完成对数据库的增删改查。其中，增删改只需要改变SQL语句的内容就能完成，然而查询略显复杂。 大概是这样 1234567Statement stat = conn.createStatement();// 准备sql语句// 注意： 字符串要用单引号'String sql = \"insert into students values('小明'\"+\",\"+\"'201616116')\";//在statement中使用字符串拼接的方式，这种方式存在诸多问题stat.execute(sql); 在Statement中使用字符串拼接的方式，这样有什么坏处呢？ 1.SQL注入。 举个栗子：一般我们执行这条语句，插入的名字和学号是变化的，我们传来的是“小明”还好，如果传了一个“小明........”后面接着其他的sql语句咋整，这个我们是没办法阻止的，人家传多少，我们执行多少。人家搞个删库的过来，哟吼，完蛋！ 2.复杂 这么一搞，我每个sql都要这么玩，这么拼接，代码量也大，也不舒服。Statement在实际过程中使用的非常的少，所以一般我们都用这个PreparedStatement 用PreparedStatement不多说直接上代码看看： 12345String sql = \"insert into students values(?,?)\";PreparedStatement pstmt = (PreparedStatement) conn.prepareStatement(sql);pstmt.setString(1, name);pstmt.setInt(2, Id);pstmt.executeUpdate(); 诶，不一样了，对于同样的语句我们如果用preparedstatement，相对原有的statement好了很多。而且这里听说有个预编译机制，性能会快那么一两点。 对于insert/delete/update都可以用executeUpdate()函数，返回int，表示有多少行受到了影响，而查询select则可以用executeQuery() 处理和显示结果接下来就是结果了，我们进行一波查询或者啥的总要返回结果给java这边吧，java这边有个ResultSet这个集合类可以让stat执行完sql语句后把结果返回给我们。 ResultSet这东西其实是个借口来着，我们一般常用的就只有里面几个方法，比如我们要取某个表的学号，就直接getInt(/*字段列数或者是字段名*/)学号在里面是第一列，就写个1也可以，学号在里面叫ID，就直接填”ID”也行。如果要传出来的是String的，就用getString()。 上代码看下。 1234567ResultSet rs = s.executeQuery(sql);while (rs.next())&#123; int Id = rs.getInt(\"student_id\"); String Name = rs.getString(\"student_name\"); //一般我们在后面会把这些搞成对象，方便集中处理。（转json）....&#125; 释放资源我们创建的连接，用完了要关闭吧！我们创建的statement，这个也要关闭。我们创建的resultset，这个也要关闭。 这个时候我们就又要关闭他们了。当然我也尝试过不关闭，这可以跑，但是久而久之系统的可用资源慢慢下降整个后台性能就呵呵了。 1234rs.close();pstmt.close();conn.close();//直接调用close即可进行关闭 实际在进行close的时候也要考虑是不是空连接（查询一个不存在的表的时候），通常的做法是放进finally{...}里面，这样最后执行，然后close之前加个if判空即可。 1234567891011121314151617finally &#123; if (rs != null) &#123; try &#123; rs.close(); &#125; catch (SQLException e) &#123; /* ignored */&#125; &#125; if (ps != null) &#123; try &#123; ps.close(); &#125; catch (SQLException e) &#123; /* ignored */&#125; &#125; if (conn != null) &#123; try &#123; conn.close(); &#125; catch (SQLException e) &#123; /* ignored */&#125; &#125;&#125; 123456//如果这些不可能是空指针，可以直接try，catch，或者直接用人家封装的玩意儿 finally &#123; DbUtils.closeQuietly(rs); DbUtils.closeQuietly(ps); DbUtils.closeQuietly(conn);&#125; 差不多这样了，以上只是一些简单的执行过程，还有很多细节可以深入，数据库连接池，jdbctmplate等。在这里也mark一下，看下有空搞一搞。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"Mybatis-ORM简介","slug":"Mybatis-ORM简介","date":"2019-11-21T08:29:44.000Z","updated":"2019-11-21T08:55:54.783Z","comments":true,"path":"2019/11/21/Mybatis-ORM简介/","link":"","permalink":"http://yoursite.com/2019/11/21/Mybatis-ORM%E7%AE%80%E4%BB%8B/","excerpt":"","text":"引言参考了http://www.ruanyifeng.com/blog/2019/02/orm-tutorial.htmlhttps://my.oschina.net/u/3568681/blog/1610459 介绍 对象关系映射（Object Relational Mapping，简称ORM）是通过使用描述对象和数据库之间映射的元数据，将面向对象语言程序中的对象自动持久化到关系数据库中。本质上就是将数据从一种形式转换到另外一种形式。 面向对象编程的话如java，编程时我们习惯于将东西都看为一个个对象（Object），而在关系型数据库中，每张表的字段之间的关系其实是一个关系来的，所以我们就将其称为关系（Relation），而两者的映射就是ORM。 栗子举个栗子：一个学生，他有名字，学号，身高，体重。如果将其存在数据库中的话就是一组关系,当然这组关系（表）可以存很多学生。| 名字 | 学号 | 身高 | 体重 || :—: | :—: | :—: | :—: || 小明 | 123 | 180 | 73 | 而如果在编程过程汇总我们倾向将学生直接包装为一个类 1234567public class student&#123; private String name; private int num; private int high; private int weight; //.....setter and getter....&#125; 这个时候就很明显了，我们可以直接做一个映射如下： 数据库的表（table） –&gt; 类（class） 记录（record，行数据）–&gt; 对象（object） 字段（field）–&gt; 对象的属性（attribute） 好处这样有啥好处呢，不就是一一对应了一下？对应了一下有个好处，在jdbc的时候，我们需要写sql语句，写的不亦乐乎，而有了这个我们就可以直接不用了解sql语句了。 123//对于查询我们应该只需要调用函数即可Student student = studentmapper.select(主键还是啥的);String name = student.getname(); 而对于ORM的实现框架，目前就有springDao，mybatis,hibernated等。当然具体的实现方式大同小异，主要是围绕这个来展开，通过这个开发人员不需要知道数据库的底层，不需要写sql，而且思维切换也比较简单。而且也将事务的处理逻辑和存储的操作分开，一定程度上也是一种解耦。","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://yoursite.com/categories/Mybatis/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://yoursite.com/tags/Mybatis/"},{"name":"框架","slug":"框架","permalink":"http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"}]},{"title":"Mybatis-Mybatis是个啥","slug":"Mybatis-Mybatis是个啥","date":"2019-11-21T06:41:02.000Z","updated":"2019-11-26T12:52:28.965Z","comments":true,"path":"2019/11/21/Mybatis-Mybatis是个啥/","link":"","permalink":"http://yoursite.com/2019/11/21/Mybatis-Mybatis%E6%98%AF%E4%B8%AA%E5%95%A5/","excerpt":"","text":"引言本片文章参考了Mybatis的工作流程01mybatis工作流程图Mybatis工作流程及其原理与解析 对于Mybatis，在开发过程中也有使用，在使用过程中也发现了这玩意儿好用（配置方便），但是没有去深入思考这玩意儿除了我们用的过程中发现的优点，它还有什么优点，以及它的整个运行过程和原理，看了网上的文章还是让我有很多疑问。为此在这里进行进一步整理，也会随着自己学习过程不定期更新。 定义首先我们来看下定义，以下是百度百科的结果 MyBatis 是一款优秀的持久层框架，它支持定制化 SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生信息，将接口和 Java 的 POJOs(Plain Ordinary Java Object,普通的 Java对象)映射成数据库中的记录 JDBC和ORM相关的我也做了简单的介绍。 Mybatis-ORM简介 数据库-jdbc总结 这是参考文章整理的优点： 半自动化的ORM实现(实体类和SQL语句之间建立映射关系) SQL代码从程序代码中彻底分离，可重用 与JDBC相比，减少了50%以上的代码量 小巧灵活、简单易学，是最简单的持久化框架 提供XML标签，支持编写动态SQL 提供映射标签，支持对象与数据库的ORM字段映射 使用总体为了先有个大概的了解，先来看看总体工作流程，以下是参考文章的一个流程图。 流程 核心类里面提到了几个类是Mybatis关键的核心类，在此稍稍介绍一下： SqlSessionFactory:每个基于 MyBatis 的应用都是以一个 SqlSessionFactory 的实例为中心的。SqlSessionFactory 的实例可以通过 SqlSessionFactoryBuilder 获得。而 SqlSessionFactoryBuilder 则可以从 XML 配置文件或通过Java的方式构建出 SqlSessionFactory 的实例。SqlSessionFactory 一旦被创建就应该在应用的运行期间一直存在，建议使用单例模式或者静态单例模式。（tips：一个SqlSessionFactory对应配置文件中的一个环境（environment），如果你要使用多个数据库就配置多个环境分别对应一个SqlSessionFactory。） SqlSession：SqlSession是一个接口，它有2个实现类，分别是DefaultSqlSession(默认使用)以及SqlSessionManager。SqlSession通过内部存放的执行器（Executor）来对数据进行CRUD。此外SqlSession不是线程安全的，因为每一次操作完数据库后都要调用close对其进行关闭，官方建议通过try-finally来保证总是关闭SqlSession。 Executor：Executor（执行器）接口有两个实现类，其中BaseExecutor有三个继承类分别是BatchExecutor（重用语句并执行批量更新），ReuseExecutor（重用预处理语句prepared statements），SimpleExecutor（普通的执行器）。以上三个就是主要的Executor。通过下图可以看到Mybatis在Executor的设计上面使用了装饰者模式，我们可以用CachingExecutor来装饰前面的三个执行器目的就是用来实现缓存。 配置12345678910111213141516171819202122232425262728293031&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!-- 开启自动扫描，方便mapper类的注入 --&gt; &lt;context:component-scan base-package=\"dong.GW.list.Dao.Mapper\"/&gt;&lt;!-- 数据源的配置，数据源就是你要在哪个数据库找东西 --&gt; &lt;bean id=\"dataSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\"&gt; &lt;!-- 加载驱动 --&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/ToDoList?useUnicode=true&amp;amp;characterEncoding=UTF-8&amp;amp;useJDBCCompliantTimezoneShift=true&amp;amp;useLegacyDatetimeCode=false&amp;amp;serverTimezone=UTC \"/&gt; &lt;property name=\"username\" value=\"username\"/&gt; &lt;property name=\"password\" value=\"password\"/&gt; &lt;/bean&gt;&lt;!-- sqlsessionfactory的配置 --&gt; &lt;bean id=\"sessionFactory\" name=\"sessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;property name=\"typeAliasesPackage\" value=\"dong.GW.list.Dao.Entity\"/&gt; &lt;/bean&gt; &lt;!-- 映射配置 --&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"sqlSessionFactoryBeanName\" value=\"sessionFactory\"/&gt; &lt;property name=\"basePackage\" value=\"dong.GW.list.Dao.Mapper\"/&gt; &lt;/bean&gt;&lt;/beans&gt;","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://yoursite.com/categories/Mybatis/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://yoursite.com/tags/Mybatis/"},{"name":"框架","slug":"框架","permalink":"http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"}]},{"title":"【转载】Redis-JeisPool.returnResource()被弃用","slug":"Redis-JedisPool.returnResource()","date":"2019-11-17T10:21:54.000Z","updated":"2019-11-17T13:00:46.822Z","comments":true,"path":"2019/11/17/Redis-JedisPool.returnResource()/","link":"","permalink":"http://yoursite.com/2019/11/17/Redis-JedisPool.returnResource()/","excerpt":"","text":"拷别人代码来跑的时候发现这个函数不能用，发现自己依赖导的是3.1，而人家的依赖导的版本是2.1，看了这篇文章才知道版本不支持了。 原文链接https://my.oschina.net/xiehongfei/blog/646125 自Jedis3.0版本后jedisPool.returnResource()遭弃用,官方重写了Jedis的close方法用以代替； 代码如下： 1234567891011121314151617/** * @deprecated starting from Jedis 3.0 this method will not be exposed. * Resource cleanup should be done using @see &#123;@link redis.clients.jedis.Jedis#close()&#125; */ @Override @Deprecated public void returnResource(final Jedis resource) &#123; if (resource != null) &#123; try &#123; resource.resetState(); returnResourceObject(resource); &#125; catch (Exception e) &#123; returnBrokenResource(resource); throw new JedisException(\"Could not return the resource to the pool\", e); &#125; &#125; &#125; 官方建议应用redis.clients.jedis#Jedis的close方法进行资源回收，官方代码如下： 123456789101112@Overridepublic void close() &#123; if (dataSource != null) &#123; if (client.isBroken()) &#123; this.dataSource.returnBrokenResource(this); &#125; else &#123; this.dataSource.returnResource(this); &#125; &#125; else &#123; client.close(); &#125;&#125;","categories":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/tags/Redis/"},{"name":"JAVA","slug":"JAVA","permalink":"http://yoursite.com/tags/JAVA/"}]},{"title":"Spring-spring的bean","slug":"Spring-Bean","date":"2019-11-17T10:21:54.000Z","updated":"2019-11-17T12:55:11.279Z","comments":true,"path":"2019/11/17/Spring-Bean/","link":"","permalink":"http://yoursite.com/2019/11/17/Spring-Bean/","excerpt":"","text":"引言本文参考了https://www.awaimai.com/2596.htmljava bean是个什么概念什么是bean 因为最近在做东西的时候做着做着多想了一步，一问自己bean这样配了之后有啥用，一时间还真就没法解释清楚，不禁陷入哲学般的沉思，不知道怎么解释，说到底还是基础知识不牢固，在这里再整理一遍。 什么是Bean官方文档的解释： In Spring, the objects that form the backbone of your application and that are managed by the Spring IoC container are called beans. A bean is an object that is instantiated, assembled, and otherwise managed by a Spring IoC container. 人话翻译： 在 Spring 中，构成应用程序主干并由Spring IoC容器管理的对象称为bean。bean是一个由Spring IoC容器实例化、组装和管理的对象。 提取关键信息可以得出 bean是对象，一个或者多个不限定 bean由Spring中一个叫IoC的东西管理 我们的应用程序由一个个bean构成 bean的规范 所有属性为private 提供默认构造方法 提供getter和setter 实现serializable接口 配置引起我思考的一个问题就是 我们在xml中配置了这么个东西，到底是干什么的。 1&lt;bean id=\"bean1\" class=\"demo2.bean1\"/&gt; 一开始反应是将这个类的对象实例化过程交给Spring IOC来管理。 这话不假，但是我一般会怎么用呢？里面的配置干啥的呢？ 对之前做的笔记进行整理发现，其实也很简单。 我们从头到尾整理一遍： 为什么要有这个配置首先我们有这么两个类 1234567891011121314public class Computer &#123; private String cpu; // CPU型号 private int ram; // RAM大小，单位GB public Computer(String cpu, int ram) &#123; this.cpu = cpu; this.ram = ram; &#125;&#125;public class Person &#123; private Computer computer; ......&#125; 很明显，Perso类需要用到Computer类，在这里我们发现，我们并没有直接new一个computer对象出来。在这里我们要先解释一下为什么要用IOC，而不是直接new。这玩意儿在大部分情况下都可以减少我们很多代码量。 为什么要用IOC有一个宽泛的说法是解耦，这里放一张图，大概是这么个意思，具体的场景也没遇到过，牛逼喊出来就好了。 没有解耦 没有解耦 解耦 解耦了 A需要用到B，C,D,E等等类的时候，我们需要一个个去new吗，不，太累了，用IOC吧，人家帮我搞的好好的，我只需要负责用就好了，因为一个new如果是简单的new还好，如果new的时候还要初始化很多东西，然后还不止一个要new，这个时候IOC的好处就体现出来了。 怎么用（配置）我们一般有三种方式来配置这个东西： 1.XML方式显示配置我们在配置好这个东西之后 12&lt;bean id=\"bean1\" class=\"demo2.bean1\"/&gt;&lt;!--如果需要的话还可以在里面加一些其他默认配置，比如名字默认是无名氏啥的--&gt; 这样一配，人家spring就可以通过你这个找到你这个类然后帮你自动new了。 自动new的话怎么样拿到人家的new的对象呢。 1234//通过工厂类拿到相应配置中的beanApplicationContext apc = new ClassPathXmlApplicationContext(\"configofdemo.xml\");userservice us=(userservice)apc.getBean(\"user\"); //获得 当然大部分情况下不会这样用，就和上面提到的，如果A需要newB,C,D,E,F。而且每一个都需要部分初始化配置，这个时候就可以这么来。 12345678910111213141516171819&lt;bean id=\"B\" class=\"xml.B\"&gt; &lt;!--初始化对象--&gt; &lt;property name=\"p1\" value=\"Hello\"/&gt; &lt;property name=\"p2\" value=\"Xml\"/&gt;&lt;/bean&gt;&lt;bean id=\"C\" class=\"xml.C\"&gt; &lt;property name=\"p1\" value=\"Hello\"/&gt; &lt;property name=\"p2\" value=\"Xml\"/&gt;&lt;/bean&gt;&lt;bean id=\"D\" class=\"xml.D\"&gt; &lt;property name=\"p1\" value=\"Hello\"/&gt; &lt;property name=\"p2\" value=\"Xml\"/&gt;&lt;/bean&gt;&lt;bean id=\"A\" class=\"xml.A\"&gt; &lt;!--其实这个也是初始化--&gt; &lt;property name=\"依赖A\" ref=\"A\"/&gt; &lt;property name=\"依赖B\" ref=\"B\"/&gt; &lt;property name=\"依赖C\" ref=\"C\"/&gt;&lt;/bean&gt; 这里面的property也有其他的变化的，也有什么构造器啊啥的，具体的不细说，之前笔记有记一点，先放上来。 ref= 用于对象属性的时候用 property 用于有set和get方法的时候调用 construction用于构造函数 p名称空间属性注入复杂的： 数组、list—–property内用list —简单类型用value，复杂用ref； set——property内用set， map——property内用map——然后用entry 属性设置key 和value； properties——property里面用props———prop key=？ 标签间写内容 类似的有一个通过代码装配bean的，这个我不太熟，先把标题放着，后续更新 2.Java代码配置bean待更新………… 3.自动化装配这个和xml比的话，xml如果是你做了一道菜（创建一个类），然后写一个制作方法（xml配置bean），给springIOC容器让他帮你new的话。自动化装配就是自动记录你做菜的过程（创建类的时候就帮你搞定），其他啥都不用管。 写个比喻好累，不比喻了。其实这个就是注解。在类前面打上一个@component注解你就相当于写了个&lt;bean id=&quot;B&quot; class=&quot;xml.B&quot;&gt; 123456@Component(\"beanid\") //没有名字默认按类名作为idpublic class Aimpl implements A &#123; private B b; ...&#125; 一个类自己bean有了，但是这个类依赖了其他类的时候我们也需要设置的，本来在xml里面我们配置一个 1&lt;property name=\"依赖C\" ref=\"C\"/&gt; 但是现在我们只需要一个@Autowerid就好了，上面代码就变成了 123456@Component(\"bean_id\") //没有名字默认按类名作为idpublic class Aimpl implements A &#123; @Autowerid private B b; ...&#125; 对于类注解的话常用的有,大家都是bean，只不过名字不同罢了 repository———Dao类注解 service——-service类注解 controller——–controller注解 component——-普通 对于属性的注解 普通属性———value 类———autowerid（自动默认按类型注入autowerid下的qualifier后带名称精确定位（注解id——等于resource 最后在xml里面开启注解扫描。这个扫描的话呢就是相当于自动扫描你包下的所有类，只要是在类名和属性名前面打了相关的注解的话就把它自动作为bean导入到这里面，而不用手动去写。 123456789&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!--后面的basepackage是我们要扫描的包--&gt; &lt;context:component-scan base-package=\"com.stalkers.impl\"/&gt;&lt;/bean&gt; 本文： 关于注解方面还不够详细，具体后续会加一篇。 java代码配置bean未总结 部分地方未完善 有问题欢迎指正","categories":[{"name":"Spring","slug":"Spring","permalink":"http://yoursite.com/categories/Spring/"}],"tags":[{"name":"框架","slug":"框架","permalink":"http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"},{"name":"JAVA","slug":"JAVA","permalink":"http://yoursite.com/tags/JAVA/"},{"name":"Spring","slug":"Spring","permalink":"http://yoursite.com/tags/Spring/"}]},{"title":"Redis-发布者订阅者","slug":"Redis-发布者订阅者","date":"2019-11-16T10:21:54.000Z","updated":"2019-11-17T06:29:59.182Z","comments":true,"path":"2019/11/16/Redis-发布者订阅者/","link":"","permalink":"http://yoursite.com/2019/11/16/Redis-%E5%8F%91%E5%B8%83%E8%80%85%E8%AE%A2%E9%98%85%E8%80%85/","excerpt":"","text":"引言本文参考了https://blog.csdn.net/clh604/article/details/19754939https://blog.csdn.net/gududedabai/article/details/80326129 简介 为了解耦发布者(publisher)和订阅者(subscriber)之间的关系，Redis 使用了 channel (频道)作为两者的中介 —— 发布者将信息直接发布给 channel ，而 channel 负责将信息发送给适当的订阅者，发布者和订阅者之间没有相互关系，也不知道对方的存在： 实现介绍订阅者订阅频道 订阅 发布者在相应频道发信息就好，完全不需要管谁订阅了，自动会发送到每个订阅者手中 发布 主要命令样例开启一个客户端先进行订阅。然后在另一个客户端在相应频道发布消息，两个客户端内容如下图。 订阅 发布消息 PUBLISH 发布消息 实现（源码）PUBLISH的命令主要有这两个步骤 使用给定的频道作为键，在 redisServer.pubsub_channels 字典中查找记录了订阅这个频道的所有客户端的链表，遍历这个链表，将消息发布给所有订阅者。 遍历 redisServer.pubsub_patterns 链表，将链表中的模式和给定的频道进行匹配，如果匹配成功，那么将消息发布到相应模式的客户端当中。 PUBLISH 命令的实际实现由 pubsubPublishMessage 函数完成，它的完整定义如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 发送消息 int pubsubPublishMessage(robj *channel, robj *message) &#123; int receivers = 0; struct dictEntry *de; listNode *ln; listIter li; /* Send to clients listening for that channel */ // 向频道的所有订阅者发送消息 de = dictFind(server.pubsub_channels,channel); if (de) &#123; list *list = dictGetVal(de); // 取出所有订阅者 listNode *ln; listIter li; // 遍历所有订阅者， 向它们发送消息 listRewind(list,&amp;li); while ((ln = listNext(&amp;li)) != NULL) &#123; redisClient *c = ln-&gt;value; addReply(c,shared.mbulkhdr[3]); addReply(c,shared.messagebulk); addReplyBulk(c,channel); // 打印频道名 addReplyBulk(c,message); // 打印消息 receivers++; // 更新接收者数量 &#125; &#125; /* Send to clients listening to matching channels */ // 向所有被匹配模式的订阅者发送消息 if (listLength(server.pubsub_patterns)) &#123; listRewind(server.pubsub_patterns,&amp;li); // 取出所有模式 channel = getDecodedObject(channel); while ((ln = listNext(&amp;li)) != NULL) &#123; pubsubPattern *pat = ln-&gt;value; // 取出模式 // 如果模式和 channel 匹配的话 // 向这个channel的订阅者发送消息 if (stringmatchlen((char*)pat-&gt;pattern-&gt;ptr, sdslen(pat-&gt;pattern-&gt;ptr), (char*)channel-&gt;ptr, sdslen(channel-&gt;ptr),0)) &#123; addReply(pat-&gt;client,shared.mbulkhdr[4]); addReply(pat-&gt;client,shared.pmessagebulk); addReplyBulk(pat-&gt;client,pat-&gt;pattern); // 打印被匹配的模式 addReplyBulk(pat-&gt;client,channel); // 打印频道名 addReplyBulk(pat-&gt;client,message); // 打印消息 receivers++; // 更新接收者数量 &#125; &#125; decrRefCount(channel); // 释放用过的 channel &#125; return receivers; // 返回接收者数量 &#125; SUBSCRIBE 订阅频道 实现（源码）数据结构 123456struct redisServer &#123; // 省略 ... dict *pubsub_channels; // Map channels to list of subscribed clients // 省略 ... &#125;; pubsub_channels是个字典，字典的键就是一个个 channel ，而字典的值则是一个链表，链表中保存了所有订阅这个 channel 的客户端。(haspmap之类)，所以要订阅就现需要在里面加上自己 函数 pubsubSubscribeChannel 是 SUBSCRIBE 命令的底层实现，它完成了将客户端添加到订阅链表中的工作： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// 订阅指定频道 // 订阅成功返回 1 ，如果已经订阅过，返回 0 int pubsubSubscribeChannel(redisClient *c, robj *channel) &#123; struct dictEntry *de; list *clients = NULL; int retval = 0; /* Add the channel to the client -&gt; channels hash table */ /*dictadd函数其实就是在字典里面加键值对，channel作为键，null为值 这个函数会检查是否存在现有的channel，没有的话就创建一个，加到客户端的pubsub里面 */ //---------------关键-------------------- if (dictAdd(c-&gt;pubsub_channels,channel,NULL) == DICT_OK) &#123; retval = 1; //函数的作用是增加对对象的引用，我不知道要干啥,不过我知道引用为0会被删掉 incrRefCount(channel); /* Add the client to the channel -&gt; list of clients hash table */ // 将 client 添加到订阅给定 channel 的链表中 // 这个链表是一个哈希表的值，哈希表的键是给定 channel // 这个哈希表保存在 server.pubsub_channels 里 //-----------------关键------------------- de = dictFind(server.pubsub_channels,channel); if (de == NULL) &#123; // 如果 de 等于 NULL // 表示这个客户端是首个订阅这个 channel 的客户端 // 那么创建一个新的列表， 并将它加入到哈希表中 clients = listCreate(); dictAdd(server.pubsub_channels,channel,clients); incrRefCount(channel); &#125; else &#123; // 如果 de 不为空，就取出这个 clients 链表 clients = dictGetVal(de); &#125; // 将客户端加入到链表中 listAddNodeTail(clients,c); &#125; /* Notify the client */ addReply(c,shared.mbulkhdr[3]); addReply(c,shared.subscribebulk); // 返回订阅的频道 addReplyBulk(c,channel); // 返回客户端当前已订阅的频道和模式数量的总和 addReplyLongLong(c,dictSize(c-&gt;pubsub_channels)+listLength(c-&gt;pubsub_patterns)); return retval; &#125; dictAdd(...)源码 1234567891011121314151617181920212223242526272829303132333435363738394041424344/*将给定键值对添加到字典中 * 只有给定键 key 不存在于字典时，添加操作才会成功 * 添加成功返回 DICT_OK , 失败返回 DICT_ERR */int dictAdd(dict *d, void *key, void *val)&#123; /* 新建节点,entry=null */ dictEntry *entry = dictAddRaw(d,key,NULL); /* 如果entry不为null，返回1 */ if (!entry) return DICT_ERR; /* 给节点赋值 */ dictSetVal(d, entry, val); /*先添加键再添加值*/ /* 操作成功，返回0 */ return DICT_OK;&#125;dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)&#123; long index; dictEntry *entry; dictht *ht; /* 指向字典中的hash表 */ /* 判断字典此时是否正在rehash */ if (dictIsRehashing(d)) _dictRehashStep(d); /* 如果新元素（key）已经存在，那么index=-1，否则index就是新元素的下标值 */ if ((index = _dictKeyIndex(d, key, dictHashKey(d,key), existing)) == -1) return NULL; /* 给新的entry分配内存空间并且保存新的entry， * 在这里，会将新的元素放在hash表的表头 */ /* 如果字典这是正在rehash，那么会将entry添加到ht[1]中去；否则添加到ht[0] */ ht = dictIsRehashing(d) ? &amp;d-&gt;ht[1] : &amp;d-&gt;ht[0]; entry = zmalloc(sizeof(*entry)); entry-&gt;next = ht-&gt;table[index]; ht-&gt;table[index] = entry; ht-&gt;used++;/* 更新hash表中used属性的值 */ /* 设置entry的key */ dictSetKey(d, entry, key); return entry;&#125; PSUBSCRIBE 订阅模式（多个频道） 实现（源码）数据结构 和 redisServer.pubsub_channels 属性类似， redisServer.pubsub_patterns 属性用于保存所有被订阅的模式，和 pubsub_channels 不同的是， pubsub_patterns 是一个链表(而不是字典)： 123456struct redisServer &#123; // ...... list *pubsub_patterns; // A list of pubsub_patterns // ...... &#125; pubsubSubscribePattern 是 PSUBSCRIBE 的底层实现，它将客户端和所订阅的模式添加到redisServer.pubsub_patterns 当中： 123456789101112131415161718192021222324252627// 订阅指定模式 // 订阅成功返回 1 ，如果已经订阅过，返回 0 int pubsubSubscribePattern(redisClient *c, robj *pattern) &#123; int retval = 0; // 向 c-&gt;pubsub_patterns 中查找指定 pattern // 如果返回值为 NULL ，说明这个 pattern 还没被这个客户端订阅过 if (listSearchKey(c-&gt;pubsub_patterns,pattern) == NULL) &#123; retval = 1; // 添加 pattern 到客户端 pubsub_patterns listAddNodeTail(c-&gt;pubsub_patterns,pattern); incrRefCount(pattern); // 将 pattern 添加到服务器 pubsubPattern *pat; pat = zmalloc(sizeof(*pat)); pat-&gt;pattern = getDecodedObject(pattern); pat-&gt;client = c; listAddNodeTail(server.pubsub_patterns,pat); &#125; /* Notify the client */ addReply(c,shared.mbulkhdr[3]); addReply(c,shared.psubscribebulk); // 返回被订阅的模式 addReplyBulk(c,pattern); // 返回客户端当前已订阅的频道和模式数量的总和 addReplyLongLong(c,dictSize(c-&gt;pubsub_channels)+listLength(c-&gt;pubsub_patterns)); return retval; &#125; 这个的话如果每次添加都要去匹配每一个channel然后加client的话就太累了，这个东西也失去了意义，本来就是为了模式匹配的，这样一个个加，有点繁琐了。为了能让这玩意儿起作用，在publish中会在这里也遍历一次，在publish相应的执行函数中进行channel的对比，匹配上了就发。 UNSUBSCRIBE 不订阅 这个就比较随意啦，就不细讲。 TIPS个人一些理解上卡的关键点： 1.在没有一个channel的情况下是通过怎样的方式创建channel的呢？ 这个要结合源代码来看，没有channel的时候，其实也就是这个channel被首次订阅的时候，这个时候会调用dictAdd，而且是加在服务端serer.pubsub上的，细节可以看上面的源码，。 2.如果自己没订阅的话别人订阅了，那在pubsub里面有其他人订阅了了岂不是自己就订阅不了了？ 这个是我自己眼角膜不要了，我没看清楚的是在订阅相关的函数中第一个if条件中的pubsub是c-&gt;pubsub_channels，也就是说是客户端的一个字典，客户端的字典只是存了自己订阅的，里面的值啥都没有的。而下面的de的判断是server.pubsub，也就是远程的，那里面的list就会保存所有订阅了相应channel的客户端了。 3.为什么有ht[0]，ht[1]，没有2和3或4吗？ 通过搜索资料发现，dicth哈希字典里面自带了两个哈希表，0和1，这个人家里面本来就有，没得杠。dictht0是直接存储哈希表的地方， dictht1在rehash中用到。里面的一些详细问题暂时还没有参透，日后再说。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/tags/Redis/"},{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"IOTA-介绍","slug":"IOTA-介绍","date":"2019-11-14T10:21:54.000Z","updated":"2019-11-16T08:36:50.076Z","comments":true,"path":"2019/11/14/IOTA-介绍/","link":"","permalink":"http://yoursite.com/2019/11/14/IOTA-%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"引言本文参考了https://www.jianshu.com/p/45c72f6cb417https://www.iotachina.com/what-is-iota 简介 IOTA是为物联网（IoT）而设计的一个革命性的新型交易结算和数据转移层。它基于新型的分布式账本——Tangle（缠结）。Tangle能够克服现有区块链设计中的低效性，并为去中心化P2P系统共识的达成创造了一种新方法。通过IOTA进行转账不需要支付手续费，这是首例。这也就意味着，无论是多小额的支付都能通过IOTA完成。 IOTA的Tangle和区块链有什么不同？最小单位 区块链的最小单位是区块（可能包含多个交易） IOTA的最小单位是一次交易 架构他们是两个完全独立的架构，但是却建立在同一种规则之上。 IOTA共识机制创新 区块链共识是通过一个非常严格的机制完成的，区块链中添加下一个区块需要多方进行竞争，并获取区块奖励或交易手续费。正因如此，共识和交易生成是分离开的，并且由网络的一小部分人来完成，通常会设置较高门槛（就像比特币一样），这样会导致进一步的中心化。 在IOTA系统中，网络中的每位参与者都能进行交易并且积极参与共识。更具体点说，你直接定位了两笔交易（主交易和分支交易），且间接在子tangle中定位其它交易。通过这种方式，验证就能同步进行，网络能够保持完全去中心化，不需要矿工传递信任，也不需要支付交易手续费。 https://www.jianshu.com/p/ced888ba7d3a确认和共识讲解 手续费 基于比特币的交易需要支付矿工手续费，这里的矿工就是建立区块的节点。在未来小微支付广泛存在的物联网场景中，这种交易方式并不适用，因为这个手续费会大概率超过微小交易本身的价值，这种情况是非常不合理的。 同时，由于矿工的存在，使得比特币系统不可避免地拥有了节点二元性的特点 节点二元性：一类节点是参与交易的，而一类节点是参与确认交易的。这种二元性将会造成资源分配问题和公平性问题。 解决 ： 在IOTA中，每一笔新交易发生之前，该笔交易的节点首先要选择之前两个旧交易进行验证。验证通过后，该交易和被验证的两笔交易绑定。也就是说，要在IOTA网络上发行交易，就要对之前的交易进行验证。参与交易的每个节点都要承担一些矿工的义务，对整个网络的交易真实性负责。 这种记账的方式，不需要矿工，也不需要大量节点验证，这就节省了手续费和算力资源。有效地消除了手续费和网络二元性的问题，更加适用于大量节点之间小额交易的物联网场景。 交易过程选择旧交易一个节点在发行一个新的交易之前，首先要选择已经发生过的两个交易进行验证。关于选择哪两个交易，是IOTA技术的关键，最简单的策略是随机选择，并且要在还未被验证过的交易中进行选择。 （关键技术，还要深入） 验证旧交易选择好旧交易后，节点会对它们进行验证。要检查交易的签名是否正确，生成该交易的工作量大小，以及是否和与之直接或间接相连的交易有冲突。如果有冲突，则重新选择旧交易；如果没有冲突，则验证通过。 绑定旧交易验证通过后，节点将新生成的交易与已被验证的交易进行绑定。绑定过程需要做一点PoW计算，类似于比特币中的矿工，需要找到一个随机数满足如下条件：该随机数和被验证交易中的某个数值连接成新的字符串，该字符串对应的哈希值应满足某个固定格式。 （待补充，然后呢，需要广播吗》） （待补充）每次交易干了啥数据结构 IOTA的和其他代币最根本的区别是底层数据结构的不同。其他代币大多是用区块链存储交易数据，而IOTA则是采用了缠结Tangle作为其底层的数据结构。 Tangle Tangle是一种存储交易数据的有向无环图（Directed Acyclic Graph, DAG），其基本结构如图1所示。 （待加图） 风险交易冲突 IOTA通过交易权重解决这个问题。 每个交易在生成时，都会附带两个权重值。 自有权重，为3的指数，固定不变； 累计权重，是其后续绑定交易自有权重的累加，随着交易的增多而变大。 （待补充）权重怎么算，权重怎么起作用 pow共识机制 交易在被验证的时候，两个权重值是重要参考指标。累计权重越大的交易，意味着其可信度越高。在交易冲突发生的时候，会比较两个交易的累计权重，并舍弃那个累计权重较小的交易及其分支，后续如果遇到合适的时机会会再加上。","categories":[{"name":"IOTA","slug":"IOTA","permalink":"http://yoursite.com/categories/IOTA/"}],"tags":[{"name":"IOTA","slug":"IOTA","permalink":"http://yoursite.com/tags/IOTA/"},{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"论文","slug":"论文","permalink":"http://yoursite.com/tags/%E8%AE%BA%E6%96%87/"},{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"Redis-常用命令","slug":"Redis-常用命令","date":"2019-11-14T10:21:54.000Z","updated":"2019-11-16T08:24:53.428Z","comments":true,"path":"2019/11/14/Redis-常用命令/","link":"","permalink":"http://yoursite.com/2019/11/14/Redis-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"引言参考 https://blog.csdn.net/weixx3/article/details/92188775暂未附上声明 #","categories":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/tags/Redis/"},{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"命令","slug":"命令","permalink":"http://yoursite.com/tags/%E5%91%BD%E4%BB%A4/"}]},{"title":"java-拆箱装箱","slug":"java-拆箱装箱","date":"2019-11-09T10:21:54.000Z","updated":"2019-11-17T12:55:42.247Z","comments":true,"path":"2019/11/09/java-拆箱装箱/","link":"","permalink":"http://yoursite.com/2019/11/09/java-%E6%8B%86%E7%AE%B1%E8%A3%85%E7%AE%B1/","excerpt":"","text":"前言本文转载于http://www.cnblogs.com/dolphin0520/p/3780005.html并根据自己的理解方式做了表达上的修改 概念Java SE5之前，如果要生成一个数值为10的Integer对象，必须这样进行： 1Integer i = new Integer(10); 而在从Java SE5开始就提供了自动装箱的特性，如果要生成一个数值为10的Integer对象，只需要这样就可以了： 1Integer i = 10; 这个过程中会自动根据数值创建对应的 Integer对象，这就是装箱。 而拆箱就是将包装器类型的转化为基本数据类型的一个过程 12Integer i = 10; //装箱int n = i; //拆箱 实现原理Integer为例： 66通过javap -c 对.java文件进行反编译得到.class文件得到如下结果 在装箱的时候自动调用的是Integer的valueOf(int)方法 在拆箱的时候自动调用的是Integer的intValue方法 其他的数据类型也都是按照相似的方式拆箱装箱的 源码解析","categories":[{"name":"JAVA基础","slug":"JAVA基础","permalink":"http://yoursite.com/categories/JAVA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://yoursite.com/tags/JAVA/"},{"name":"数据类型","slug":"数据类型","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"}]},{"title":"leetcode-最大回文子串","slug":"leetcode-最大回文子串","date":"2019-11-09T08:07:50.000Z","updated":"2019-11-09T08:58:45.629Z","comments":true,"path":"2019/11/09/leetcode-最大回文子串/","link":"","permalink":"http://yoursite.com/2019/11/09/leetcode-%E6%9C%80%E5%A4%A7%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2/","excerpt":"","text":"暴力法不多做详解 1.中心扩展法此方法主要思想:通过查找以字符串中以某个字符为中心的回文子串是有多长，来得到每个回文子串的大小。对于这个子串，我们就从中心出发，向两边扩展，如果扩展后还是回文串，那么继续扩展，直到不是回文串，我们就可以将子串长度记录下来了。对于向两边扩展，我们可以通过一个下标来表示（也可以用指针），p1和p2。 现在有个问题，aabbaa和aabaa都是回文串，所以在打代码的时候就要稍稍做个处理。 两种情况 回文子串是奇数个，那么中心点就是一个字符，所以初始状态，p1和p2是指向同一个字符的。 回文子串是偶数个，那么中心就是两个字符，所以初始状态，p1和p2是指向两个相同字符的。 对于两种情况的处理打代码稍稍注意下就好了，问题不大。（这个方法暂无代码……） 2.动态规划主要思想：对于i到j是否是回文子串，我们只需要判断两个问题： i位置和j位置两个字符是否相同 如果相同了就判断i+1和j-1是否是个回文窜 有了这两点就没啥问题了 公式如下： 1dp[i][j] = dp[i+1][j-1] 这里的dp[i][j]存放的是boolean类型的，下面的dp存的是回文串长度 因为i一定会比j小，所以在二维数组上的操作要多多注意 一段比较原始的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public String longestPalindrome(String s) &#123; if (s.length() &lt;=1)&#123; return s; &#125; int len = s.length(); int dp[][] = new int[len][len]; //初始化dp数组，主要是a和aa这种先准备好 //dp数组每个格子存放当前i到j的回文子串长度 for (int i = 0;i &lt; len;i++)&#123; dp[i][i] = 1; //i到i（单个字符）就是个回文串 if (i != len-1)&#123; //aa也是个回文串 if (s.charAt(i) == s.charAt(i+1))&#123; dp[i][i+1] = 2; &#125; &#125; &#125; //这个循环和是纵列在外，横行在内 for (int i = 2; i &lt; len; i ++)&#123; //这里是j到i for (int j = 0;j &lt; i-1;j++)&#123; if (s.charAt(j) == s.charAt(i))&#123; if (dp[j+1][i-1] == 0)&#123; dp[j][i] = dp[j+1][i-1]; &#125;else &#123; dp[j][i] = dp[j+1][i-1] +2 ; &#125; &#125; &#125; &#125; //把最大子串给截出来 int left = 0; int right = 0; int maxlen = 0; for (int i =0;i&lt; len;i++)&#123; for (int j = i;j &lt; len;j++)&#123; if (dp[i][j] &gt; maxlen)&#123; maxlen = dp[i][j]; left = i; right = j; &#125; &#125; &#125; return s.substring(left,right+1); &#125; 3.Manacher算法（待更）","categories":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/categories/leetcode/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"},{"name":"动态规划","slug":"动态规划","permalink":"http://yoursite.com/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"}]},{"title":"Linux下权限的修改设置","slug":"linux-permission","date":"2019-11-08T08:46:26.000Z","updated":"2019-11-09T07:03:19.907Z","comments":true,"path":"2019/11/08/linux-permission/","link":"","permalink":"http://yoursite.com/2019/11/08/linux-permission/","excerpt":"","text":"修改文件权限1$ chmod -R 777 files 1.先来讲讲数字777代表的是三个级别的身份owner/group/others 对于每个级别都有三个不同的权限 r 读权限read 4，100 w 写权限write 2，010 x 操作权限execute 1， 001 如果rwx都可以，就对三个数进行相加，等于7。这个就相当于3bit的位来表示单个级别身份的权限，某个位上的1表示有这个位代表的权限，0表示没有 2.接着讲讲 R对于R的话其实表示：对目前目录下的所有文件与子目录进行相同的权限变更(即以递回的方式逐个变更) 3.其他当然除了 1chmod -R XXX file.txt 也有其他的方式，主要是依据owner/group/others三个用户来的。 栗子：设置文件拥有者权限为可写，组合为可读，其他用户删去可执行权限 1chmod u+w,g+r,o-x files.txt own对应 u group对应 g other对应 o 所有对应 a 此处自己只是列举了自己常用的，部分深入的细节没有完全解释清楚，网上也有大片的参考。 详细的可以百度chmod","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"命令","slug":"命令","permalink":"http://yoursite.com/tags/%E5%91%BD%E4%BB%A4/"},{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"初来乍到","slug":"myblog-creation","date":"2019-11-08T05:54:13.000Z","updated":"2019-11-17T05:35:04.491Z","comments":false,"path":"2019/11/08/myblog-creation/","link":"","permalink":"http://yoursite.com/2019/11/08/myblog-creation/","excerpt":"","text":"第一次建站，若有问题欢迎大家指正。 有问题欢迎大家发送邮件和我探讨交流172544714@qq.com","categories":[{"name":"Helloworld","slug":"Helloworld","permalink":"http://yoursite.com/categories/Helloworld/"}],"tags":[{"name":"HEXO","slug":"HEXO","permalink":"http://yoursite.com/tags/HEXO/"}]}]}