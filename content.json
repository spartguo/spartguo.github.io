{"meta":{"title":"禹哥小站","subtitle":"","description":"","author":"spartguo","url":"http://yoursite.com","root":"/"},"pages":[{"title":"Categories","date":"2019-11-07T08:52:01.000Z","updated":"2019-11-07T08:56:04.345Z","comments":false,"path":"Categories/index.html","permalink":"http://yoursite.com/Categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-11-07T07:33:35.000Z","updated":"2019-11-07T07:59:32.665Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"英文社区中的部分缩略词","slug":"language","date":"2020-03-17T06:37:05.000Z","updated":"2020-03-17T06:46:00.957Z","comments":true,"path":"2020/03/17/language/","link":"","permalink":"http://yoursite.com/2020/03/17/language/","excerpt":"","text":"引言最近做毕设进入到Discord进行讨论交流的时候发现有很多英文缩略，大家好像很习以为常，在stackoverflow上也没见那么多，方便后续查找，在这里整理一波，基本都是整理网上的。 词组缩写tbh：to be honest 老實說Tbh, I don’t think Jerry will be able to graduate this year.老實說，我不覺得 Jerry 今年可以畢業。 lmao：laugh my ass off 笑到不行、超爆笑大家應該都看過 “lol” (laugh out loud) 這個表示大笑的三個字母，但除了 lol，其實你也可以用 lmao 呦！字面上的意思就是「把屁股都笑掉了」，就代表超級好笑、笑到不行的意思！ A: That annoying professor fell off his chair in front of 300 students!B: lmao!A: 那個超討人厭的教授在 300 個學生面前從椅子上跌下來耶！B: 也太爆笑了吧！ btw：by the way 順帶一提John is so rude! How can he do something like that? Btw, there’s no way I’m going to forgive him.John 也太沒禮貌了吧！他怎麼可以做出那種事？順帶一提，我是絕對不會原諒他的。 ttyl：talk to you later 晚點聊Gotta get going. Ttyl!我差不多要走了，晚點聊喔！ idk：I don’t know 我不知道Idk if she’s gonna make it tonight or not.我不知道她今晚有沒有辦法來耶。 aka：as known as 也就是、以…為人所知Chris, aka Alex’s boyfriend, is going to move to another country.Chris，也就是 Alex的男朋友，即將搬去另一個國家了。 單字縮寫上面主要是词组缩写，下面还有一些单词缩写 plz：please 拜託Daddy, can you come pick me up? Plz!爸爸，你可不可以來接我？拜託！ thx：thanks 謝謝Can you drop this to the postoffice on your way home? Thx!你回家的時候可以順便幫我把這個拿到郵局嗎？謝謝！ tmr：tomorrow 明天Let’s catch up tmr.我們明天見面聊聊吧。 ppl：people 人們、大家I feel like I really get along with these ppl.我覺得我跟這群人很合得來。","categories":[{"name":"语言","slug":"语言","permalink":"http://yoursite.com/categories/%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"语言","slug":"语言","permalink":"http://yoursite.com/tags/%E8%AF%AD%E8%A8%80/"},{"name":"社区","slug":"社区","permalink":"http://yoursite.com/tags/%E7%A4%BE%E5%8C%BA/"}]},{"title":"linux-端口","slug":"linux-端口","date":"2020-03-17T02:52:54.000Z","updated":"2020-03-17T03:31:52.295Z","comments":true,"path":"2020/03/17/linux-端口/","link":"","permalink":"http://yoursite.com/2020/03/17/linux-%E7%AB%AF%E5%8F%A3/","excerpt":"","text":"引言最近在搞毕设，搭建ict节点的时候需要开放到一个端口，我就去网上搜寻资料，然后还差点整坏了自己的安全组，具体原因未知，有待后续进一步测试。在此整理设置端口的方法 方法一：iptables参考链接：https://www.jianshu.com/p/2ec5d16db02b iptables12345678//安装iptables$ sudo apt-get install iptables//添加安全规则 (8080为需要开放的端口)$ iptables -I INPUT -p tcp --dport 8080 -j ACCEPT//保存$ iptables-save 在完成了这个步骤的时候当下是可以进行8080端口访问的，但是如果你重启一波之后就会吧这个东西刷掉，一切恢复原样。 iptables-persistent123456//安装 iptables-persistent$ sudo apt-get install iptables-persistent//持久化规则$ sudo netfilter-persistent save$ sudo netfilter-persistent reload 持久化规则那规则在哪呢，在这 12/etc/iptables/rules.v4/etc/iptables/rules.v6 一开始安装完iptables-persistent后就没注意，直接重启（也不知道哪里看来的重启操作），然后导致我的登录接口被关闭了。后面得到腾讯云的控制台界面再进行一次重启才ok。后来想想，应该是自己在进行iptables的规则设置的时候覆盖了一些东西。 方法二：腾讯云设置安全规则因为我的服务器用的是腾讯云的，所以进入在腾讯云控制台操作的，阿里云和华为云的应该都差不多。 添加安全组我添加个安全组，一般会有选项把基本端口打开 编辑/配置安全组把你想要的端口加入到安全组中 关联安全组把你设置好的安全组和你的服务器关联起来 相对来讲，这些服务提供商给的有界面操作起来会方便点，但是多少还是要学会linux会比较好一点。毕竟搞个自己电脑上的虚拟机就还是得用回方法一。","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"命令","slug":"命令","permalink":"http://yoursite.com/tags/%E5%91%BD%E4%BB%A4/"},{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"IOTA-钱包","slug":"IOTA-钱包","date":"2020-03-12T10:00:04.000Z","updated":"2020-03-12T10:03:35.950Z","comments":true,"path":"2020/03/12/IOTA-钱包/","link":"","permalink":"http://yoursite.com/2020/03/12/IOTA-%E9%92%B1%E5%8C%85/","excerpt":"","text":"#引言 #简介关于IOTA钱包，我觉得可以理解为","categories":[{"name":"IOTA","slug":"IOTA","permalink":"http://yoursite.com/categories/IOTA/"}],"tags":[{"name":"IOTA","slug":"IOTA","permalink":"http://yoursite.com/tags/IOTA/"},{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"论文","slug":"论文","permalink":"http://yoursite.com/tags/%E8%AE%BA%E6%96%87/"},{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"spring-spring jar包的结构和依赖关系","slug":"spring-包依赖","date":"2020-02-21T07:00:01.000Z","updated":"2020-02-21T12:44:34.602Z","comments":true,"path":"2020/02/21/spring-包依赖/","link":"","permalink":"http://yoursite.com/2020/02/21/spring-%E5%8C%85%E4%BE%9D%E8%B5%96/","excerpt":"","text":"在进行项目搭建的的时候我一般都是直接别人说要什么依赖我就加什么依赖，没去想过spring的各个jar包到底是干嘛的，哪些可以不要，哪些不行，哪些负责什么功能，这些还是比较懵，所以，感觉需要整理一波。 https://blog.csdn.net/smonkeyking/article/details/82661814spring-mybatis和mybatis使用方法 mybatis-spring文档http://mybatis.org/spring/zh/index.html","categories":[{"name":"框架","slug":"框架","permalink":"http://yoursite.com/categories/%E6%A1%86%E6%9E%B6/"}],"tags":[{"name":"框架","slug":"框架","permalink":"http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"},{"name":"spring","slug":"spring","permalink":"http://yoursite.com/tags/spring/"}]},{"title":"Redis-java连接服务端Redis","slug":"Redis-java连接服务端Redis","date":"2019-12-13T13:23:59.000Z","updated":"2019-12-13T13:26:58.305Z","comments":true,"path":"2019/12/13/Redis-java连接服务端Redis/","link":"","permalink":"http://yoursite.com/2019/12/13/Redis-java%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E7%AB%AFRedis/","excerpt":"","text":"引言在服务器上安装redis安装启动配置日志 bind端口绑定 客户端连接redis下载jedis包ping一下","categories":[],"tags":[]},{"title":"区块链-比特币消费过程","slug":"区块链-比特币消费过程","date":"2019-12-13T07:19:48.000Z","updated":"2019-12-13T07:20:16.886Z","comments":true,"path":"2019/12/13/区块链-比特币消费过程/","link":"","permalink":"http://yoursite.com/2019/12/13/%E5%8C%BA%E5%9D%97%E9%93%BE-%E6%AF%94%E7%89%B9%E5%B8%81%E6%B6%88%E8%B4%B9%E8%BF%87%E7%A8%8B/","excerpt":"","text":"待写！！！","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"论文","slug":"论文","permalink":"http://yoursite.com/tags/%E8%AE%BA%E6%96%87/"}]},{"title":"区块链-共识","slug":"区块链-共识","date":"2019-12-09T09:00:01.000Z","updated":"2019-12-13T08:38:19.436Z","comments":true,"path":"2019/12/09/区块链-共识/","link":"","permalink":"http://yoursite.com/2019/12/09/%E5%8C%BA%E5%9D%97%E9%93%BE-%E5%85%B1%E8%AF%86/","excerpt":"","text":"引言今天在看IOTA的时候扯到了共识这个东西，因为一开始都是稀里糊涂的，所以没能够有很深刻的理解，在此总结一下自己目前了解的。 什么是共识概念百度一下 所谓“共识机制”，是通过特殊节点的投票，在很短的时间内完成对交易的验证和确认；对一笔交易，如果利益不相干的若干个节点能够达成共识，我们就可以认为全网对此也能够达成共识。 共识: 所有参与者的一致意见，意味着每个人都接受并支持这些决定。 机制: 建立的过程由明确的规则组成，以实现特定的目标 拜占庭将军问题和共识共识共识，大家要达成共识，肯定要一致嘛，而一致性的问题这个拜占庭将军问题很有代表性，所以也就跟风讲讲。下面是我自己总结的文字版，有点枯燥，想不枯燥可以到这里去哈哈——-漫画：什么是拜占庭将军问题？ 在很久很久以前，拜占庭是东罗马帝国的首都。那个时候罗马帝国国土辽阔，为了防御目的，因此每个军队都分隔很远，将军与将军之间只能靠信使传递消息。在打仗的时候，拜占庭军队内所有将军必需达成一致的共识，才能更好地赢得胜利，或者说至少要一半或者2/3以上将军配合才能打赢。但是，在军队内有可能存有叛徒，扰乱将军们的决定。这个要怎么解决呢？ 这个问题存在几个点： 将军可能是叛徒 信使可能是叛徒 信使可能被绑架然后假信使发假东西 要解决将军问题，第一个先要解决信息传递的安全性，这个解决方案是非对称加密技术，公钥加密，私钥解密，这个计算量有点大，古代解决不了。第二个要解决将军间的信息传递问题，古代消息传递慢这个问题解决不了，在现代就是P2P点对点传输，保证将军之间可以互相传递消息。 现代计算机和互联网让大家有了这两个条件，只要忠诚的将军多最终大家都能够得出好的决策，而且每个人说的都会被记录，谁是叛徒，一下就知道了。 但是！！！我们不知道谁先发消息，虽然大家都说要进攻，但是也要有个人带头啊！信息的发送需要个规则，这个时候为了保证公平就有个共识机制了。 至于为什么要解决这几个点，以及部分细节，可以看下这篇文章—深度剖析共识机制和拜占庭将军问题 解决的问题具体怎么个解决法后续再细品 达成一致:共识机制试图解决围绕分布式系统的最复杂问题之一：数据的真实性和准确性达成统一协议。与中心化系统不同，用户不必信任系统中的任何人。嵌入网络的协议规则确保了公共分类帐的状态总是随着大众的共识而更新。 防止双花攻击:共识机制防止任何用户重复消费，这是在比特币出现之前一直存在的数字货币问题。“双花攻击”指的是数字货币有可能被两次消费。区块链共识机制中嵌入的协议规则确保只有有效和真实的交易才记在公共透明的账簿中。随着矿工算力扩大以保护交易（以及网络），双花攻击或改变交易的指数变得越来越难。 激励机制:创建一个自我调节的无信任系统需要调动网络参与者的积极性。共识机制通过激励好的行为，在某些情况下，惩罚坏的行为者来实现这一点。比特币(Bitcoin)使用的第一种共识机制(工作量证明(Proof-of-Work))，通过奖励比特币(Bitcoins)给矿工，奖励他们每一笔交易的担保和验证。任何针对网络的行动(通过黑客攻击或双花攻击)都需要大量的算力和钱财，这些资源将更好地用于为系统工作(因为他们的努力会得到回报)，而不是针对系统。 公平公正区块链的去中心化的一个重要优势是分配授权，任何人都能在同一个基础上参与进来。公共区块链的开源特性使任何人都可以检查和验证底层源代码对网络中的所有参与者是否公平。如果你愿意，就可以轻松地设置一个节点并成为参与者甚至矿工。简而言之，共识机制确保区块链不存在区别对待。 容错机制在算法领域，容错是指分布式系统在面临威胁或故障时仍能无限运行。共识机制确保区块链是容错的，因此是可靠和一致的。 共识算法分类上面的要解决什么问题都有了我们接下来就来看看解决问题的方案，也就是共识机制。 共识算法有好多种，这里简单总结几种，部分我不是很熟，所以暂时不做深入 工作量证明（Pow）因为目前比特币是最流行的，所以拿比特币作为例子吧。 比特币交易流程发起交易广播如果你发起了一笔交易，这个时候交易是不会直接形成区块加在链上的，你广播了一笔交易大家会把交易放在一个缓存池里，然后等某个节点打包成区块。 打包区块广播因为一个区块大概可以放3000个交易，太浪费了，而且区块的形成会被控制在10分钟生成一个，所以大家会把交易放在一个缓存池里，然后等某个节点打包成区块。这个节点打包的话会有奖励，但是要先算出一个问题，这个问题很容易被验证，但是就是很难算出来。算出来了你就可以打包一个区块了。打包好后广播到所有节点。 确认交易因为一个区块加在链上是要通过计算上一个块的，所以只要这个块后面有块了，就会被确认下来，要改也要全部重新计算，成本较高，所以一般在后面接了6个块之后才认为交易被确认。 这里我个人有疑问没有解决： Q:如何保证单笔交易广播出去创建区块的人收得到呢？ 这个好像还真就没啥办法，有时候某个挖矿的人（创建区块）缓存一清，你的交易也没了，而且网络上很多交易，你的交易也有可能迟迟没被收到，所以，在过了很久之后你就要再发一下。反正重复交易不会被放到块里面。因为比特币是我有10个比特币，这10个比特币要给A5块钱，你需要有两笔交易，一笔给自己5块，一笔给A5块，所以，你同样的10块钱人家一看这个东西被花过了，就算了。 Q:单个节点解出某个问题的时候（有资格生成区块），别人也解出来了，而且都一起广播出来了咋整。 根据我的了解，计算的问题如果很快就被解出来了，也就是一个区块很快生成的话，问题的难度会被提高，很慢的话，难度就降低，这样保持10分钟生成一个区块，所以一般一个区块不会那么容易被算出来。 然后出现两个人一起打包了一些交易广播出去的情况，我这里讲一下我个人的理解，可能有点错误。因为网上大多数是说你算力高算的越快就几率越大，我在想我比你晚0.0000001s这算什么？对吧，所以我经过个人思考有这么一个想法。 在发出去的时候别人貌似也会看他们的问题难度是多少，因为每个题会有个难度系数，所以可以通过难度和验证结果来看，如果是一样的话就出现两条链，这个时候有个分叉，但是一个交易的确认是看后面有没有6个区块，所以虽然打包进入了某个块，但是这个交易还没被确认，所以不用紧张。然后分叉的链一般不会久，除非你有阴谋，下个问题会提到，因为有个约定的东西就是分叉的按照最长的链最为主链，其他的要抛弃。所以一般不会很混乱的，一起算出来一起广播，1看难度，2看链长。一旦有分叉，基本很快就会被解决， Q:如何防止矿工伪造交易？将伪造的交易打包进区块？ 一个旷工要伪造交易，一般就是双花交易或者白嫖，一种空手套白狼，一种是1块钱当两块钱花，这些情况都需要一点，就是修改交易，但是一个交易一旦被确认后面有6个区块连着，你改这一个后面6个区块很多东西要重新算，很累啊。所以啊，你得很牛逼才可以,多牛逼呢？全网51%的算力。 去个栗子：你花10个btc买了辆911，然后想白嫖，车到手了，毕竟这玩意不能追踪，所以你只要吧在网络上的你的相关交易删掉，你的钱就回来了。这个时候你自己搞一条分链，不给别人看。这条分链里面其他的都和主链一样，但是唯独没有你消费911的那笔交易。 自己的分链短的，你把这东西发出去别人肯定不认你，因为认长不认短，这时候你要拼命算，才能赶上全网其他人创建区块的速度，等到这样 就可以广播一下，你的911就是免费的了，现在可以细细品，要赶上全网其他人，要多少算力，至少要50%以上吧，这就是51%攻击，一般来说这样成本巨高，或者你可以勾结很多矿工干这事，当然成本必定更高。 权益证明（POS）(Proof of Stake):股权证明机制。 这是点点币（PPC）的创新。没有挖矿过程，在创世区块内写明了股权分配比例，之后通过转让、交易的方式（通常就是IPO），逐渐分散到用户手里，并通过“利息”的方式新增货币，实现对节点的奖励。以太坊是POW跟pos结合。 简单来说，就是一个根据用户持有货币的多少和时间（相乘得到币龄），发放利息的一个制度。现实中最典型的例子就是股票，或者是银行存款。如果用户想获得更多的货币，那么就打开客户端，让它保持在线，就能通过获得“利息”获益，同时保证网络的安全。 去个栗子：你有1000个币，在手上30天了，那你的币龄就是30*1000，然后根据你的这个币龄给你利息，当然这个利息应该是要求你建立区块啥的才可以拿。 优点PoS的好处显而易见，节省了由于竞争记账权浪费的大量算力和电费，不用挖矿，不需要大量耗费电力和能源。 同时大大缩减了达成共识的时间成本，也更去中心化，去中心化是相对的。相对于比特币等PoW类型的加密货币，PoS机制的加密货币对计算机硬件基本上没有过高要求，人人可挖矿（获得利息），不用担心算力集中导致中心化的出现（单用户通过购买获得51%的货币量，成本更高） 网络更加安全有保障。避免紧缩。PoW机制的加密货币，因为用户丢失等各种原因，可能导致通货紧缩，但是PoS机制的加密货币按一定的年利率新增货币，可以有效避免紧缩出现，保持基本稳定。比特币之后，很多新币采用PoS机制，很多采用工作量证明机制的老币，也纷纷修改协议，“硬分叉”升级为PoS机制。 缺点纯PoS机制的加密货币，只能通过IPO的方式发行，这就导致“少数人”（通常是开发者）获得大量成本极低的加密货币，在利益面前，很难保证他们不会大量抛售。 PoS机制的加密货币，信用基础不够牢固。为解决这个问题，很多采用PoW+PoS的双重机制，通过PoW挖矿发行加密货币，使用PoS维护网络稳定。或者采用DPoS机制，通过社区选举的方式，增强信任。而正因为这样，有钱的人，币多的人（节点），获得记账权的机率更大，这会使得共识成为少数有钱人的垄断游戏，从而失去公正性； 总结完优缺点，这里我有疑问： 在pos机制下，区块如何被创建呢？毕竟总不可能人在家中坐，啥也不干，就有钱吧！ 区块多人创建的话情况怎么解决？ 验证机制也是要多人验证吗？ 这些疑问估计要单独拎出来和部分pos的实现一起总结了。 暂时总结到这里，有空再加 股份授权证明（DPOS）、验证池共识机制（Pool） 有啥问题希望大佬们能指正。 深度剖析共识机制和拜占庭将军问题共识算法指南:什么是共识机制?什么是共识机制区块链中，交易被如何打包进区块什么是51% 攻击(双花攻击)股权证明机制（PoS）是什么区块链杂谈—共识机制","categories":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/"}],"tags":[{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"论文","slug":"论文","permalink":"http://yoursite.com/tags/%E8%AE%BA%E6%96%87/"},{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"服务器-nginx配置","slug":"服务器-nginx配置","date":"2019-12-03T05:51:13.000Z","updated":"2020-04-13T16:12:59.564Z","comments":true,"path":"2019/12/03/服务器-nginx配置/","link":"","permalink":"http://yoursite.com/2019/12/03/%E6%9C%8D%E5%8A%A1%E5%99%A8-nginx%E9%85%8D%E7%BD%AE/","excerpt":"","text":"引言原来的服务器上的博客静态资源是通过nginx进行访问的，由于图片我之前是放在七牛云上面，但是访问图片的测试域名随时一个月就到期了，自己暂时也没有备案好的域名，所以希望说能够有个长期的落脚点，想着把图片也一起放到服务器的某个地方，然后通过特定的url通过nginx进行访问，但是在搞的过程中连配置文件都找了有一会儿，都不知道怎么搞。在此简单整理一波 nginx是啥百度百科如是说 Nginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，在BSD-like 协议下发行。其特点是占有内存少，并发能力强，事实上nginx的并发能力在同类型的网页服务器中表现较好。 提取关键点，就是个服务器，这玩意儿最大的特点就是有个代理机制。 如上图，这个就是常见的一个模式，科学上网就是这么个运作模式，你访问google，但是有个墙挡住了，这个时候你就可以通过一个国外的，不会被墙挡住的服务器去访问，这个国外的服务器就充当了个代理的角色。服务器不知道谁要来访问我，我只需要知道有人来，我提供服务就好了。 而反向代理就是反过来，客户访问你，你有很多个服务，可能我图片放了一个地方，视频放了一个地方，这个时候你只需要发请求到代理服务器哪里，然后代理服务器nginx会自动解析url看看要发到哪里去，客户端不需要知道你发到哪里。 主要命令启动，左边那个其实就是sbin里面的，右边的是配置文件，我的配置文件在/etc/nginx里面 1nginx -c /usr/local/nginx/conf/nginx.conf 检查版本 1nginx -v 重新启动 1nginx -s reload 关于停止 正常停止或关闭Nginx 1nginx -s quit 快速停止或关闭Nginx 1nginx -s stop 查看进程的方式 1ps -ef|grep nginx 从容停止 1kill -QUIT 进程号 快速停止 1kill -TERM 进程号 强制停止 1pkill -9 nginx 下面几个和最上面非查看进程的方式异曲同工 安装/删除安装安装没啥问题，直接用 1apt-get install nginx 删除在搞完某个配置的时候，想重启，结果有点问题，应该是配置上的问题，我个人比较懒，就想着直接删了重来，结果呵呵，遇到了写问题 痛苦根源一开始想着彻底卸载，直接调用 1sudo apt-get --purge remove nginx 然后跟着部分网站说的删各种文件夹（这里主要还是没搜几个就草草上手了，以后还是要小心） 然后再装回来，看起来非常方便，很舒胡。 1sudo apt-get install install nginx 因为我要改里面的配置，所以打算搞个重启 1sudo service nginx restart 结果来一句 1job for nginx.service failed because the control process exited with error code. See “systemctl stat 更惨的是我删了重来，这个错误依然在 服务也一直开不起来 通过查阅资料这个错误主要是如下两个问题 配置文件有问题 已经启动nginx配置或者端口被占用 关于这个问题这篇文章对我有点小启发nginx启动报错 而且安装完了之后因为我删去的/usr/sbin/下的nginx文件，我输入 1nginx -v 上面提示我没有部分包，这个时候我是已经执行了安装的，我也有点奇怪为啥重新安装没有把包重新安装了呢？ 对于上面的问题，我觉得这篇文章很有帮助 记一次重装nginx时遇到的问题 因为有问题的时候瞎搞了很多步骤，时间比较紧，也就没有看到底出在哪，我的解决重点在怎么删干净，也没有截图，估计里面涉及到很多问题，导致现在部分东西没办法复现，所以后续再深入探讨。所以我就只在下面写一下如何彻底删除。只要彻底删除搞好了，再来安装就不会有这个问题了。 彻底删除经过一番查阅知道，原来彻底删除的正确姿势是这样的 删除nginx，包含配置文件 1sudo apt-get --purge remove nginx 自动移除全部不使用的软件包 1sudo apt-get autoremove 罗列出与nginx相关的软件 1dpkg --get-selections|grep nginx 可能会有nginx-common这些东西还留着，出现几个删几个，都删了，片甲不留 当然有个直接的方法，可以直接 1sudo apt-get --purge remove nginx* 查看nginx正在运行的进程，如果有就kill掉 1ps -ef |grep nginx 全局查找与nginx相关的文件，找到后就删掉 1sudo find / -name nginx* 找到文件一个个删有点累，可以来个组合命令。 1find / -name nginx* -exec rm -rf &#123;&#125; \\; 到了这一步差不多了。 主要配置这里只搞基本的东西 接下来看下配置总体情况 全局块该部分配置主要影响Nginx全局： 必须配置 指定运行worker进程的用户和组；user USERNAME [GROUPNAME]比如：user www-data; 指定nginx守护进程的pid文件pid /path/to/pid_file; 指定所有worker进程所能够打开的最大文件句柄数;worker_rlimit_nofile #; 性能优化相关的配置 worker进程的个数：通常应该略小于CPU物理核心数;worker_processes # 优点：提升缓存的命中率worker_cpu_affinity cpumask…;例子：worker_cpu_affinity 00000001 00000010 00000100; 计时器解析度：降低此值，可减少gettimeofday()系统调用的次数timer_resolution 指明worker进程的nice值worker_priority number; event块该部分配置主要影响Nginx服务器与用户的网络连接，主要包括： 基本配置 master调度用户请求至各worker进程时使用的负载均衡锁；on表示能让多个worker轮流的、序列化的去响应新请求;accept_mutex {off|on}; accept_mutex用到的锁文件路径;lock_file; 指明使用的事件模型：建议让Nginx自行选择;use [epoll|rtsig|select|poll]; 设定单个worker进程所能够处理的最大并发连接数量worker_connections #; 调试定位问题 是否以守护进程方式运行nginx, 调试时应该设置为offdaemon {on|off}; 是否以master/worker模型来运行nginx；调试时可以设置为offmaster_process {on|off}; error_log 位置 级别；若要使用debug级别，需要在编译nginx时使用–with-debug选项;error_log file | stderr | syslog:server=address[,parameter=value] | memory:size [debug | info | notice | warn | error | crit | alert | emerg]; 常用配置 worker_processes worker_connections worker_cpu_affinity worker_priority http块http {}: 由ngx_http_core_module模块所引入； 基本设置在这里有一些基本设置，因为细节暂时没有用到，到时候再说，可以先放默认的设置上来。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354http &#123; ## # Basic Settings ## sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; # server_tokens off; # server_names_hash_bucket_size 64; # server_name_in_redirect off; include /etc/nginx/mime.types; default_type application/octet-stream; ## # SSL Settings ## ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE ssl_prefer_server_ciphers on; ## # Logging Settings ## access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ## # Gzip Settings ## gzip on; gzip_disable \"msie6\"; # gzip_vary on; # gzip_proxied any; # gzip_comp_level 6; # gzip_buffers 16 8k; # gzip_http_version 1.1; # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; ## # Virtual Host Configs ## include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*;&#125; 有问题可以参考下面两篇 Nginx基本功能及其原理linux服务基础之nginx配置详解 server块这里就是重点的配置的地方了，第一个要找到配置文件，因为一开始我是很懵的，大家都在nginx.conf里面，我在ubuntu里面安装的nginx的server{}块没有在nginx.conf的配置文件里面，反而在/etc/nginx/sites-available里面的default里面。 然后就是一些配置，以为杂七杂八的东西很多，且很多东西需要一个具体场景可能才会需要到，所以这里就简单整理一些基本的 listenlisten指令有三种配置方法： 1、listen address[:port] [ default_server ] [ ssl ]; 2、listen port [ default_server ] [ ssl ]; 3、listen unix:path [ default_server ] [ ssl ]; 使用示例： listen *:80 | *:8000; ###监听所有80和8000端口 listen 192.168.1.10；###监听具体IP的所有端口上的连接 listen 8000；###监听具体端口上的所有IP连接，等同于listen *:8000; server_name设置虚拟主机名称。可以设置多个name语法：server_name name…;例如： server_name myserver.com www.myserver.com; 因为我是在我自己的服务器上定位静态资源，不是代理，所以直接 1server_name localhost 然后里面貌似还可以用正则。 root指定根目录路径。语法：root path; 示例： 123location /picture/ &#123; root /myspace/blog;&#125; 这个的意思是url是/picture开头的，直接到这里来，然后这个root指引客户到/myspace/blog/picture里面拿东西 这个东西也可以直接在server写。我的部分静态资源就是这么请求的。 error_page设置网站的错误页面，语法为：error_page code … [=[response]]uri; code：要处理的HTTP错误代码 response：将code指定的错误代码转换为新的错误代码 uri：错误页面的路径或者网站地址，这个uri是相对于root设置的根路径而言的。 示例： 1error_page 404 /404.html; allow基于IP的访问控制： 1allow address | CIDR | unix |all; 设置允许访问的IP范围 1deny address | CIDR | unix:| all; 12345location /t/ &#123; root /data/www/vhost2/; allow 172.16.100.120; deny all;&#125; 仅允许172.16.100.120这个IP地址访问 index入口可以解析的文件类型 栗子： 1index index.html index.php index.htm proxy_pass这个是在location块里面的，这个的意思是一旦有url和这个location匹配了，就直接把请求转到这个url里面去 1proxy_pass http://127.0.0.1:80; proxy_set_header这个是把客户端需要转发到后端服务器的头部一起转发过去 12proxy_set_header Host $host; proxy_set_header X-Forwarder-For $remote_addr; proxy_redirect这个功能很强大，当上游服务器返回的响应是重定向或刷新请求（如HTTP响应码是301或者302）时，proxy_redirect可以重设HTTP头部的location或refresh字段。 这个http头部的字段我不是很了解，简单查了下资料发现这个主要就是拿来跳转的。 而如果不写这个的话我们登录某个url-A，A转发给B，B发了个重定向给我们，就会在location头里面把B给带上，这样不太好，本来我就没办法访问B的或者本来B就不想让用户直接知道的，这样把B暴露了。 具体的操作可以是类似 1proxy_redirect B A 这样我们就可以啦，当然这只是一种情况，其他情况也有，具体可以参考下 Nginx反向代理中使用proxy_redirect重定向url 因为自己暂时也用不到那么多，所以暂时就整理自己需要的，后续有需要再继续更新。需要查找可以看这个Nginx基础入门之proxy反向代理常用配置项说明 静态文件我的博客就是个静态文件夹，直接通过nginx访问的。然后我不想更改端口来访问我的图片，所以我就在location那边多加了一个/blog_pictures，这样比如我想访问url:mysite/blog_pictures/pic1.png，它就会去/myblog/blog_pictures下找这张照片 12345678910111213141516171819202122server &#123; listen 80 default_server; listen [::]:80 default_server; root /myblog/blogs; # Add index.php to the list if you are using PHP index index.html index.htm index.nginx-debian.html; server_name localhost; location / &#123; # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ =404; &#125; location /blog_pictures &#123; root /myblog; &#125;&#125; 如有问题，欢迎指正。 //todoalias he roothttps://www.cnblogs.com/liran123/p/9189449.html 本文参考了Nginx可以做什么？看完这篇你就懂了Job for nginx.service failed because the control process exited with error code. See “systemctl statnginx启动失败问题集锦linux彻底删除nginxLinux下nginx 的常用命令Nginx基本功能及其原理linux服务基础之nginx配置详解Nginx关于server块和location块的配置当“服务器上部署多个Web应用”，使用Nginx反向代理配置","categories":[],"tags":[{"name":"服务器","slug":"服务器","permalink":"http://yoursite.com/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"数据库-jdbc总结","slug":"数据库-jdbc总结","date":"2019-11-21T11:51:39.000Z","updated":"2019-12-09T06:15:09.651Z","comments":true,"path":"2019/11/21/数据库-jdbc总结/","link":"","permalink":"http://yoursite.com/2019/11/21/%E6%95%B0%E6%8D%AE%E5%BA%93-jdbc%E6%80%BB%E7%BB%93/","excerpt":"","text":"引言本片文章参考自https://blog.csdn.net/jungle_rao/article/details/81274720https://www.cnblogs.com/javazs/p/7825316.html 介绍惯例，来段百度百科 Java数据库连接，（Java Database Connectivity，简称JDBC）是Java语言中用来规范客户端程序如何来访问数据库的应用程序接口，提供了诸如查询和更新数据库中数据的方法。 对于jdbc有如下图来解释比较好 说白了jdbc其实是一个规范来的，规范了我java要操作数据库要怎么操作你都要给我个统一，对数据库的操作，你只需要关心如何操作JDBC API而不用考虑不同的数据库操作不同，或者部分字段类型不同。 而且人家做好了很多java的数据类型到数据库字段的类型的映射，比如String对应数据库的char和varchar。 举个栗子： 1select name from students where id = 2; 因为你是调用jdbc的java api的，本来name的类型是char，但是数据库的char和java的char不太一样，所以需要转，这个时候jdbc已经帮你转好了。 使用因为jdbc只是个规范，所以我们在操作不同的数据库要下载不同的jar包，里面有满足jdbc规范的针对某个特定数据库的驱动类。（ps：有时候也叫jdbc驱动，之前一直搞不清这些概念，233333） 这个驱动类实质上是实现了java.sql.Driver接口的一个类查看官网文档如下： 担心凭借自己低分飘过的六级理解错，所以我谷歌翻译了一下 Modifier and Type Method and Description boolean acceptsURL(String url) 检索驱动程序是否认为它可以打开与给定URL的连接 Connection connect(String url, Properties info) 尝试建立到给定URL的数据库连接 int getMajorVersion( 检索驱动程序的主版本号。 int getMinorVersion() 获取驱动程序的次要版本号 Logger getParentLogger() 返回此驱动程序使用的所有Logger的父Logger。 DriverPropertyInfo[] getPropertyInfo(String url, Properties info) 获取有关此驱动程序可能的属性的信息。 boolean jdbcCompliant() 报告此驱动程序是否为正版JDBC Compliant™驱动程序 通过jdbc驱动和数据库操作的主要过程如下： 加载驱动首先要加载初始化驱动类，这个过程其实就是讲驱动类加载到我们的JVM里面。关于类加载过程可以到到这里看看 12//这里以Mysql为例Class.forName(\"com.mysql.jdbc.Driver\"); 为什么其他类我直接就可以搞，人家会自动触发加载，这个为啥要手动呢？因为这个加载过程中其实是为了运行里面的静态代码块来对驱动进行初始化的，至于为什么这样我也不深入了，只知道不这样会抛异常，后续有空再瞅一下。 建立连接我们在上面已经了解过有个接口叫connect(String url, Properties info)可以帮助我们连接到指定url的数据库。 使用Driver直接建立连接12345678//1.加载oracle驱动类，并实例化 Driver driver = (Driver) Class.forName(\"oracle.jdbc.driver.OracleDriver\").newInstance(); //2.创建真实的数据库连接： String url = \"jdbc:oracle:thin:@127.0.0.1:1521:xe\"; Properties props = new Properties(); props.put(\"user\", \"louluan\"); props.put(\"password\", \"123456\"); Connection connection = driver.connect(url, props); 在1和2之间我们也可以利用上面的测试接口，看看我们的url是否符合这个数据库的协议。然后再进行连接。 在连接过程中也发现了一个问题，就是这个连接单个数据库的时候没问题，但是连接多个数据库的时候我们就得搞多个Driver了，很麻烦。 DriverManager建立连接解决方式就是来个DriverManager，用来管理我们的Driver。这个东西挺厉害，所有的驱动类都被他管着，他也可以注册/注销Driver（这个细节可以看参考的第二篇博客），想怎么玩怎么玩，驱动类初期一加载初始化然后就会自动注册到DriverManager中让他管理。而且我们的某个数据库的Driver被注销了之后，重新通过DriverManger进行getDriver，就和没有进行初始化驱动类一个结果，抛异常。 这个DriverManager有个静态方法getDriver，可以通过传过来的URL，返回可以打开URL的Driver。(这个过程其实是DriverManager通过遍历每一个Driver的acceptsURL(url)判断这个url是符合哪一个的。 而为了更进一步的方便，有个getConnection 12Driver driver = DriverManager.getDriver(url); Connection connection = driver.connect(url, props); 也等价于 12Class.forName(\"oracle.jdbc.driver.OracleDriver\"); Connection connection = DriverManager.getConnection(url, props); 如果我们经常使用某个驱动，我们可以 12//设置值系统变量jdbc.drivers System.setProperty(\"jdbc.drivers\", \"oracle.jdbc.driver.OracleDriver\"); 这样，在DriverManager第一次使用的时候就会首先加载这个驱动类。因为DriverManager会在第一次加载的时候执行静态代码块初始化这个管理类 具体DriverManager的API可以看这里 通常我们我们也用这种方式 1Connection c = DriverManager.getConnection(\"jdbc:mysql://127.0.0.1:3306/exam?characterEncoding=UTF-8\", \"root\", \"admin\"); 执行SQL语句创建Statement这东西是也是一个接口类来的，它里面有很多函数我们可以通过connection的createStatement（）函数来获得statement对象。 Statement对象创建之后，可以执行SQL语句，完成对数据库的增删改查。其中，增删改只需要改变SQL语句的内容就能完成，然而查询略显复杂。 大概是这样 1234567Statement stat = conn.createStatement();// 准备sql语句// 注意： 字符串要用单引号'String sql = \"insert into students values('小明'\"+\",\"+\"'201616116')\";//在statement中使用字符串拼接的方式，这种方式存在诸多问题stat.execute(sql); 在Statement中使用字符串拼接的方式，这样有什么坏处呢？ 1.SQL注入。 举个栗子：一般我们执行这条语句，插入的名字和学号是变化的，我们传来的是“小明”还好，如果传了一个“小明........”后面接着其他的sql语句咋整，这个我们是没办法阻止的，人家传多少，我们执行多少。人家搞个删库的过来，哟吼，完蛋！ 2.复杂 这么一搞，我每个sql都要这么玩，这么拼接，代码量也大，也不舒服。Statement在实际过程中使用的非常的少，所以一般我们都用这个PreparedStatement 用PreparedStatement不多说直接上代码看看： 12345String sql = \"insert into students values(?,?)\";PreparedStatement pstmt = (PreparedStatement) conn.prepareStatement(sql);pstmt.setString(1, name);pstmt.setInt(2, Id);pstmt.executeUpdate(); 诶，不一样了，对于同样的语句我们如果用preparedstatement，相对原有的statement好了很多。而且这里听说有个预编译机制，性能会快那么一两点。 对于insert/delete/update都可以用executeUpdate()函数，返回int，表示有多少行受到了影响，而查询select则可以用executeQuery() 处理和显示结果接下来就是结果了，我们进行一波查询或者啥的总要返回结果给java这边吧，java这边有个ResultSet这个集合类可以让stat执行完sql语句后把结果返回给我们。 ResultSet这东西其实是个借口来着，我们一般常用的就只有里面几个方法，比如我们要取某个表的学号，就直接getInt(/*字段列数或者是字段名*/)学号在里面是第一列，就写个1也可以，学号在里面叫ID，就直接填”ID”也行。如果要传出来的是String的，就用getString()。 上代码看下。 1234567ResultSet rs = s.executeQuery(sql);while (rs.next())&#123; int Id = rs.getInt(\"student_id\"); String Name = rs.getString(\"student_name\"); //一般我们在后面会把这些搞成对象，方便集中处理。（转json）....&#125; 释放资源我们创建的连接，用完了要关闭吧！我们创建的statement，这个也要关闭。我们创建的resultset，这个也要关闭。 这个时候我们就又要关闭他们了。当然我也尝试过不关闭，这可以跑，但是久而久之系统的可用资源慢慢下降整个后台性能就呵呵了。 1234rs.close();pstmt.close();conn.close();//直接调用close即可进行关闭 实际在进行close的时候也要考虑是不是空连接（查询一个不存在的表的时候），通常的做法是放进finally{...}里面，这样最后执行，然后close之前加个if判空即可。 1234567891011121314151617finally &#123; if (rs != null) &#123; try &#123; rs.close(); &#125; catch (SQLException e) &#123; /* ignored */&#125; &#125; if (ps != null) &#123; try &#123; ps.close(); &#125; catch (SQLException e) &#123; /* ignored */&#125; &#125; if (conn != null) &#123; try &#123; conn.close(); &#125; catch (SQLException e) &#123; /* ignored */&#125; &#125;&#125; 123456//如果这些不可能是空指针，可以直接try，catch，或者直接用人家封装的玩意儿 finally &#123; DbUtils.closeQuietly(rs); DbUtils.closeQuietly(ps); DbUtils.closeQuietly(conn);&#125; 差不多这样了，以上只是一些简单的执行过程，还有很多细节可以深入，数据库连接池，jdbctmplate等。在这里也mark一下，看下有空搞一搞。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"Mybatis-ORM简介","slug":"Mybatis-ORM简介","date":"2019-11-21T08:29:44.000Z","updated":"2019-11-21T08:55:54.783Z","comments":true,"path":"2019/11/21/Mybatis-ORM简介/","link":"","permalink":"http://yoursite.com/2019/11/21/Mybatis-ORM%E7%AE%80%E4%BB%8B/","excerpt":"","text":"引言参考了http://www.ruanyifeng.com/blog/2019/02/orm-tutorial.htmlhttps://my.oschina.net/u/3568681/blog/1610459 介绍 对象关系映射（Object Relational Mapping，简称ORM）是通过使用描述对象和数据库之间映射的元数据，将面向对象语言程序中的对象自动持久化到关系数据库中。本质上就是将数据从一种形式转换到另外一种形式。 面向对象编程的话如java，编程时我们习惯于将东西都看为一个个对象（Object），而在关系型数据库中，每张表的字段之间的关系其实是一个关系来的，所以我们就将其称为关系（Relation），而两者的映射就是ORM。 栗子举个栗子：一个学生，他有名字，学号，身高，体重。如果将其存在数据库中的话就是一组关系,当然这组关系（表）可以存很多学生。| 名字 | 学号 | 身高 | 体重 || :—: | :—: | :—: | :—: || 小明 | 123 | 180 | 73 | 而如果在编程过程汇总我们倾向将学生直接包装为一个类 1234567public class student&#123; private String name; private int num; private int high; private int weight; //.....setter and getter....&#125; 这个时候就很明显了，我们可以直接做一个映射如下： 数据库的表（table） –&gt; 类（class） 记录（record，行数据）–&gt; 对象（object） 字段（field）–&gt; 对象的属性（attribute） 好处这样有啥好处呢，不就是一一对应了一下？对应了一下有个好处，在jdbc的时候，我们需要写sql语句，写的不亦乐乎，而有了这个我们就可以直接不用了解sql语句了。 123//对于查询我们应该只需要调用函数即可Student student = studentmapper.select(主键还是啥的);String name = student.getname(); 而对于ORM的实现框架，目前就有springDao，mybatis,hibernated等。当然具体的实现方式大同小异，主要是围绕这个来展开，通过这个开发人员不需要知道数据库的底层，不需要写sql，而且思维切换也比较简单。而且也将事务的处理逻辑和存储的操作分开，一定程度上也是一种解耦。","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://yoursite.com/categories/Mybatis/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://yoursite.com/tags/Mybatis/"},{"name":"框架","slug":"框架","permalink":"http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"}]},{"title":"Mybatis-Mybatis是个啥","slug":"Mybatis-Mybatis是个啥","date":"2019-11-21T06:41:02.000Z","updated":"2019-12-09T06:21:57.676Z","comments":true,"path":"2019/11/21/Mybatis-Mybatis是个啥/","link":"","permalink":"http://yoursite.com/2019/11/21/Mybatis-Mybatis%E6%98%AF%E4%B8%AA%E5%95%A5/","excerpt":"","text":"引言本片文章参考了Mybatis的工作流程01mybatis工作流程图Mybatis工作流程及其原理与解析 对于Mybatis，在开发过程中也有使用，在使用过程中也发现了这玩意儿好用（配置方便），但是没有去深入思考这玩意儿除了我们用的过程中发现的优点，它还有什么优点，以及它的整个运行过程和原理，看了网上的文章还是让我有很多疑问。为此在这里进行进一步整理，也会随着自己学习过程不定期更新。 定义首先我们来看下定义，以下是百度百科的结果 MyBatis 是一款优秀的持久层框架，它支持定制化 SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生信息，将接口和 Java 的 POJOs(Plain Ordinary Java Object,普通的 Java对象)映射成数据库中的记录 JDBC和ORM相关的我也做了简单的介绍。 Mybatis-ORM简介 数据库-jdbc总结 这是参考文章整理的优点： 半自动化的ORM实现(实体类和SQL语句之间建立映射关系) SQL代码从程序代码中彻底分离，可重用 与JDBC相比，减少了50%以上的代码量 小巧灵活、简单易学，是最简单的持久化框架 提供XML标签，支持编写动态SQL 提供映射标签，支持对象与数据库的ORM字段映射 使用总体为了先有个大概的了解，先来看看总体工作流程，以下是参考文章的一个流程图。 核心类里面提到了几个类是Mybatis关键的核心类，在此稍稍介绍一下： SqlSessionFactory:每个基于 MyBatis 的应用都是以一个 SqlSessionFactory 的实例为中心的。SqlSessionFactory 的实例可以通过 SqlSessionFactoryBuilder 获得。而 SqlSessionFactoryBuilder 则可以从 XML 配置文件或通过Java的方式构建出 SqlSessionFactory 的实例。SqlSessionFactory 一旦被创建就应该在应用的运行期间一直存在，建议使用单例模式或者静态单例模式。（tips：一个SqlSessionFactory对应配置文件中的一个环境（environment），如果你要使用多个数据库就配置多个环境分别对应一个SqlSessionFactory。） SqlSession：SqlSession是一个接口，它有2个实现类，分别是DefaultSqlSession(默认使用)以及SqlSessionManager。SqlSession通过内部存放的执行器（Executor）来对数据进行CRUD。此外SqlSession不是线程安全的，因为每一次操作完数据库后都要调用close对其进行关闭，官方建议通过try-finally来保证总是关闭SqlSession。 Executor：Executor（执行器）接口有两个实现类，其中BaseExecutor有三个继承类分别是BatchExecutor（重用语句并执行批量更新），ReuseExecutor（重用预处理语句prepared statements），SimpleExecutor（普通的执行器）。以上三个就是主要的Executor。通过下图可以看到Mybatis在Executor的设计上面使用了装饰者模式，我们可以用CachingExecutor来装饰前面的三个执行器目的就是用来实现缓存。 配置12345678910111213141516171819202122232425262728293031&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!-- 开启自动扫描，方便mapper类的注入 --&gt; &lt;context:component-scan base-package=\"dong.GW.list.Dao.Mapper\"/&gt;&lt;!-- 数据源的配置，数据源就是你要在哪个数据库找东西 --&gt; &lt;bean id=\"dataSource\" class=\"org.springframework.jdbc.datasource.DriverManagerDataSource\"&gt; &lt;!-- 加载驱动 --&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/ToDoList?useUnicode=true&amp;amp;characterEncoding=UTF-8&amp;amp;useJDBCCompliantTimezoneShift=true&amp;amp;useLegacyDatetimeCode=false&amp;amp;serverTimezone=UTC \"/&gt; &lt;property name=\"username\" value=\"username\"/&gt; &lt;property name=\"password\" value=\"password\"/&gt; &lt;/bean&gt;&lt;!-- sqlsessionfactory的配置 --&gt; &lt;bean id=\"sessionFactory\" name=\"sessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;property name=\"typeAliasesPackage\" value=\"dong.GW.list.Dao.Entity\"/&gt; &lt;/bean&gt; &lt;!-- 映射配置 --&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"sqlSessionFactoryBeanName\" value=\"sessionFactory\"/&gt; &lt;property name=\"basePackage\" value=\"dong.GW.list.Dao.Mapper\"/&gt; &lt;/bean&gt;&lt;/beans&gt;","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://yoursite.com/categories/Mybatis/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"http://yoursite.com/tags/Mybatis/"},{"name":"框架","slug":"框架","permalink":"http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"}]},{"title":"【转载】Redis-JeisPool.returnResource()被弃用","slug":"Redis-JedisPool.returnResource()","date":"2019-11-17T10:21:54.000Z","updated":"2019-11-17T13:00:46.822Z","comments":true,"path":"2019/11/17/Redis-JedisPool.returnResource()/","link":"","permalink":"http://yoursite.com/2019/11/17/Redis-JedisPool.returnResource()/","excerpt":"","text":"拷别人代码来跑的时候发现这个函数不能用，发现自己依赖导的是3.1，而人家的依赖导的版本是2.1，看了这篇文章才知道版本不支持了。 原文链接https://my.oschina.net/xiehongfei/blog/646125 自Jedis3.0版本后jedisPool.returnResource()遭弃用,官方重写了Jedis的close方法用以代替； 代码如下： 1234567891011121314151617/** * @deprecated starting from Jedis 3.0 this method will not be exposed. * Resource cleanup should be done using @see &#123;@link redis.clients.jedis.Jedis#close()&#125; */ @Override @Deprecated public void returnResource(final Jedis resource) &#123; if (resource != null) &#123; try &#123; resource.resetState(); returnResourceObject(resource); &#125; catch (Exception e) &#123; returnBrokenResource(resource); throw new JedisException(\"Could not return the resource to the pool\", e); &#125; &#125; &#125; 官方建议应用redis.clients.jedis#Jedis的close方法进行资源回收，官方代码如下： 123456789101112@Overridepublic void close() &#123; if (dataSource != null) &#123; if (client.isBroken()) &#123; this.dataSource.returnBrokenResource(this); &#125; else &#123; this.dataSource.returnResource(this); &#125; &#125; else &#123; client.close(); &#125;&#125;","categories":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/tags/Redis/"},{"name":"JAVA","slug":"JAVA","permalink":"http://yoursite.com/tags/JAVA/"}]},{"title":"Spring-spring的bean","slug":"Spring-Bean","date":"2019-11-17T10:21:54.000Z","updated":"2019-12-09T06:13:18.310Z","comments":true,"path":"2019/11/17/Spring-Bean/","link":"","permalink":"http://yoursite.com/2019/11/17/Spring-Bean/","excerpt":"","text":"引言本文参考了https://www.awaimai.com/2596.htmljava bean是个什么概念什么是bean 因为最近在做东西的时候做着做着多想了一步，一问自己bean这样配了之后有啥用，一时间还真就没法解释清楚，不禁陷入哲学般的沉思，不知道怎么解释，说到底还是基础知识不牢固，在这里再整理一遍。 什么是Bean官方文档的解释： In Spring, the objects that form the backbone of your application and that are managed by the Spring IoC container are called beans. A bean is an object that is instantiated, assembled, and otherwise managed by a Spring IoC container. 人话翻译： 在 Spring 中，构成应用程序主干并由Spring IoC容器管理的对象称为bean。bean是一个由Spring IoC容器实例化、组装和管理的对象。 提取关键信息可以得出 bean是对象，一个或者多个不限定 bean由Spring中一个叫IoC的东西管理 我们的应用程序由一个个bean构成 bean的规范 所有属性为private 提供默认构造方法 提供getter和setter 实现serializable接口 配置引起我思考的一个问题就是 我们在xml中配置了这么个东西，到底是干什么的。 1&lt;bean id=\"bean1\" class=\"demo2.bean1\"/&gt; 一开始反应是将这个类的对象实例化过程交给Spring IOC来管理。 这话不假，但是我一般会怎么用呢？里面的配置干啥的呢？ 对之前做的笔记进行整理发现，其实也很简单。 我们从头到尾整理一遍： 为什么要有这个配置首先我们有这么两个类 1234567891011121314public class Computer &#123; private String cpu; // CPU型号 private int ram; // RAM大小，单位GB public Computer(String cpu, int ram) &#123; this.cpu = cpu; this.ram = ram; &#125;&#125;public class Person &#123; private Computer computer; ......&#125; 很明显，Perso类需要用到Computer类，在这里我们发现，我们并没有直接new一个computer对象出来。在这里我们要先解释一下为什么要用IOC，而不是直接new。这玩意儿在大部分情况下都可以减少我们很多代码量。 为什么要用IOC有一个宽泛的说法是解耦，这里放一张图，大概是这么个意思，具体的场景也没遇到过，牛逼喊出来就好了。 没有解耦 解耦 A需要用到B，C,D,E等等类的时候，我们需要一个个去new吗，不，太累了，用IOC吧，人家帮我搞的好好的，我只需要负责用就好了，因为一个new如果是简单的new还好，如果new的时候还要初始化很多东西，然后还不止一个要new，这个时候IOC的好处就体现出来了。 怎么用（配置）我们一般有三种方式来配置这个东西： 1.XML方式显示配置我们在配置好这个东西之后 12&lt;bean id=\"bean1\" class=\"demo2.bean1\"/&gt;&lt;!--如果需要的话还可以在里面加一些其他默认配置，比如名字默认是无名氏啥的--&gt; 这样一配，人家spring就可以通过你这个找到你这个类然后帮你自动new了。 自动new的话怎么样拿到人家的new的对象呢。 1234//通过工厂类拿到相应配置中的beanApplicationContext apc = new ClassPathXmlApplicationContext(\"configofdemo.xml\");userservice us=(userservice)apc.getBean(\"user\"); //获得 当然大部分情况下不会这样用，就和上面提到的，如果A需要newB,C,D,E,F。而且每一个都需要部分初始化配置，这个时候就可以这么来。 12345678910111213141516171819&lt;bean id=\"B\" class=\"xml.B\"&gt; &lt;!--初始化对象--&gt; &lt;property name=\"p1\" value=\"Hello\"/&gt; &lt;property name=\"p2\" value=\"Xml\"/&gt;&lt;/bean&gt;&lt;bean id=\"C\" class=\"xml.C\"&gt; &lt;property name=\"p1\" value=\"Hello\"/&gt; &lt;property name=\"p2\" value=\"Xml\"/&gt;&lt;/bean&gt;&lt;bean id=\"D\" class=\"xml.D\"&gt; &lt;property name=\"p1\" value=\"Hello\"/&gt; &lt;property name=\"p2\" value=\"Xml\"/&gt;&lt;/bean&gt;&lt;bean id=\"A\" class=\"xml.A\"&gt; &lt;!--其实这个也是初始化--&gt; &lt;property name=\"依赖A\" ref=\"A\"/&gt; &lt;property name=\"依赖B\" ref=\"B\"/&gt; &lt;property name=\"依赖C\" ref=\"C\"/&gt;&lt;/bean&gt; 这里面的property也有其他的变化的，也有什么构造器啊啥的，具体的不细说，之前笔记有记一点，先放上来。 ref= 用于对象属性的时候用 property 用于有set和get方法的时候调用 construction用于构造函数 p名称空间属性注入复杂的： 数组、list—–property内用list —简单类型用value，复杂用ref； set——property内用set， map——property内用map——然后用entry 属性设置key 和value； properties——property里面用props———prop key=？ 标签间写内容 类似的有一个通过代码装配bean的，这个我不太熟，先把标题放着，后续更新 2.Java代码配置bean待更新………… 3.自动化装配这个和xml比的话，xml如果是你做了一道菜（创建一个类），然后写一个制作方法（xml配置bean），给springIOC容器让他帮你new的话。自动化装配就是自动记录你做菜的过程（创建类的时候就帮你搞定），其他啥都不用管。 写个比喻好累，不比喻了。其实这个就是注解。在类前面打上一个@component注解你就相当于写了个&lt;bean id=&quot;B&quot; class=&quot;xml.B&quot;&gt; 123456@Component(\"beanid\") //没有名字默认按类名作为idpublic class Aimpl implements A &#123; private B b; ...&#125; 一个类自己bean有了，但是这个类依赖了其他类的时候我们也需要设置的，本来在xml里面我们配置一个 1&lt;property name=\"依赖C\" ref=\"C\"/&gt; 但是现在我们只需要一个@Autowerid就好了，上面代码就变成了 123456@Component(\"bean_id\") //没有名字默认按类名作为idpublic class Aimpl implements A &#123; @Autowerid private B b; ...&#125; 对于类注解的话常用的有,大家都是bean，只不过名字不同罢了 repository———Dao类注解 service——-service类注解 controller——–controller注解 component——-普通 对于属性的注解 普通属性———value 类———autowerid（自动默认按类型注入autowerid下的qualifier后带名称精确定位（注解id——等于resource 最后在xml里面开启注解扫描。这个扫描的话呢就是相当于自动扫描你包下的所有类，只要是在类名和属性名前面打了相关的注解的话就把它自动作为bean导入到这里面，而不用手动去写。 123456789&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!--后面的basepackage是我们要扫描的包--&gt; &lt;context:component-scan base-package=\"com.stalkers.impl\"/&gt;&lt;/bean&gt; 本文： 关于注解方面还不够详细，具体后续会加一篇。 java代码配置bean未总结 部分地方未完善 有问题欢迎指正","categories":[{"name":"Spring","slug":"Spring","permalink":"http://yoursite.com/categories/Spring/"}],"tags":[{"name":"框架","slug":"框架","permalink":"http://yoursite.com/tags/%E6%A1%86%E6%9E%B6/"},{"name":"JAVA","slug":"JAVA","permalink":"http://yoursite.com/tags/JAVA/"},{"name":"Spring","slug":"Spring","permalink":"http://yoursite.com/tags/Spring/"}]},{"title":"Redis-发布者订阅者","slug":"Redis-发布者订阅者","date":"2019-11-16T10:21:54.000Z","updated":"2019-12-09T06:18:13.604Z","comments":true,"path":"2019/11/16/Redis-发布者订阅者/","link":"","permalink":"http://yoursite.com/2019/11/16/Redis-%E5%8F%91%E5%B8%83%E8%80%85%E8%AE%A2%E9%98%85%E8%80%85/","excerpt":"","text":"引言本文参考了https://blog.csdn.net/clh604/article/details/19754939https://blog.csdn.net/gududedabai/article/details/80326129 简介 为了解耦发布者(publisher)和订阅者(subscriber)之间的关系，Redis 使用了 channel (频道)作为两者的中介 —— 发布者将信息直接发布给 channel ，而 channel 负责将信息发送给适当的订阅者，发布者和订阅者之间没有相互关系，也不知道对方的存在： 实现介绍订阅者订阅频道 发布者在相应频道发信息就好，完全不需要管谁订阅了，自动会发送到每个订阅者手中 主要命令样例开启一个客户端先进行订阅。然后在另一个客户端在相应频道发布消息，两个客户端内容如下图。 PUBLISH 发布消息 实现（源码）PUBLISH的命令主要有这两个步骤 使用给定的频道作为键，在 redisServer.pubsub_channels 字典中查找记录了订阅这个频道的所有客户端的链表，遍历这个链表，将消息发布给所有订阅者。 遍历 redisServer.pubsub_patterns 链表，将链表中的模式和给定的频道进行匹配，如果匹配成功，那么将消息发布到相应模式的客户端当中。 PUBLISH 命令的实际实现由 pubsubPublishMessage 函数完成，它的完整定义如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 发送消息 int pubsubPublishMessage(robj *channel, robj *message) &#123; int receivers = 0; struct dictEntry *de; listNode *ln; listIter li; /* Send to clients listening for that channel */ // 向频道的所有订阅者发送消息 de = dictFind(server.pubsub_channels,channel); if (de) &#123; list *list = dictGetVal(de); // 取出所有订阅者 listNode *ln; listIter li; // 遍历所有订阅者， 向它们发送消息 listRewind(list,&amp;li); while ((ln = listNext(&amp;li)) != NULL) &#123; redisClient *c = ln-&gt;value; addReply(c,shared.mbulkhdr[3]); addReply(c,shared.messagebulk); addReplyBulk(c,channel); // 打印频道名 addReplyBulk(c,message); // 打印消息 receivers++; // 更新接收者数量 &#125; &#125; /* Send to clients listening to matching channels */ // 向所有被匹配模式的订阅者发送消息 if (listLength(server.pubsub_patterns)) &#123; listRewind(server.pubsub_patterns,&amp;li); // 取出所有模式 channel = getDecodedObject(channel); while ((ln = listNext(&amp;li)) != NULL) &#123; pubsubPattern *pat = ln-&gt;value; // 取出模式 // 如果模式和 channel 匹配的话 // 向这个channel的订阅者发送消息 if (stringmatchlen((char*)pat-&gt;pattern-&gt;ptr, sdslen(pat-&gt;pattern-&gt;ptr), (char*)channel-&gt;ptr, sdslen(channel-&gt;ptr),0)) &#123; addReply(pat-&gt;client,shared.mbulkhdr[4]); addReply(pat-&gt;client,shared.pmessagebulk); addReplyBulk(pat-&gt;client,pat-&gt;pattern); // 打印被匹配的模式 addReplyBulk(pat-&gt;client,channel); // 打印频道名 addReplyBulk(pat-&gt;client,message); // 打印消息 receivers++; // 更新接收者数量 &#125; &#125; decrRefCount(channel); // 释放用过的 channel &#125; return receivers; // 返回接收者数量 &#125; SUBSCRIBE 订阅频道 实现（源码）数据结构 123456struct redisServer &#123; // 省略 ... dict *pubsub_channels; // Map channels to list of subscribed clients // 省略 ... &#125;; pubsub_channels是个字典，字典的键就是一个个 channel ，而字典的值则是一个链表，链表中保存了所有订阅这个 channel 的客户端。(haspmap之类)，所以要订阅就现需要在里面加上自己 函数 pubsubSubscribeChannel 是 SUBSCRIBE 命令的底层实现，它完成了将客户端添加到订阅链表中的工作： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// 订阅指定频道 // 订阅成功返回 1 ，如果已经订阅过，返回 0 int pubsubSubscribeChannel(redisClient *c, robj *channel) &#123; struct dictEntry *de; list *clients = NULL; int retval = 0; /* Add the channel to the client -&gt; channels hash table */ /*dictadd函数其实就是在字典里面加键值对，channel作为键，null为值 这个函数会检查是否存在现有的channel，没有的话就创建一个，加到客户端的pubsub里面 */ //---------------关键-------------------- if (dictAdd(c-&gt;pubsub_channels,channel,NULL) == DICT_OK) &#123; retval = 1; //函数的作用是增加对对象的引用，我不知道要干啥,不过我知道引用为0会被删掉 incrRefCount(channel); /* Add the client to the channel -&gt; list of clients hash table */ // 将 client 添加到订阅给定 channel 的链表中 // 这个链表是一个哈希表的值，哈希表的键是给定 channel // 这个哈希表保存在 server.pubsub_channels 里 //-----------------关键------------------- de = dictFind(server.pubsub_channels,channel); if (de == NULL) &#123; // 如果 de 等于 NULL // 表示这个客户端是首个订阅这个 channel 的客户端 // 那么创建一个新的列表， 并将它加入到哈希表中 clients = listCreate(); dictAdd(server.pubsub_channels,channel,clients); incrRefCount(channel); &#125; else &#123; // 如果 de 不为空，就取出这个 clients 链表 clients = dictGetVal(de); &#125; // 将客户端加入到链表中 listAddNodeTail(clients,c); &#125; /* Notify the client */ addReply(c,shared.mbulkhdr[3]); addReply(c,shared.subscribebulk); // 返回订阅的频道 addReplyBulk(c,channel); // 返回客户端当前已订阅的频道和模式数量的总和 addReplyLongLong(c,dictSize(c-&gt;pubsub_channels)+listLength(c-&gt;pubsub_patterns)); return retval; &#125; dictAdd(...)源码 1234567891011121314151617181920212223242526272829303132333435363738394041424344/*将给定键值对添加到字典中 * 只有给定键 key 不存在于字典时，添加操作才会成功 * 添加成功返回 DICT_OK , 失败返回 DICT_ERR */int dictAdd(dict *d, void *key, void *val)&#123; /* 新建节点,entry=null */ dictEntry *entry = dictAddRaw(d,key,NULL); /* 如果entry不为null，返回1 */ if (!entry) return DICT_ERR; /* 给节点赋值 */ dictSetVal(d, entry, val); /*先添加键再添加值*/ /* 操作成功，返回0 */ return DICT_OK;&#125;dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)&#123; long index; dictEntry *entry; dictht *ht; /* 指向字典中的hash表 */ /* 判断字典此时是否正在rehash */ if (dictIsRehashing(d)) _dictRehashStep(d); /* 如果新元素（key）已经存在，那么index=-1，否则index就是新元素的下标值 */ if ((index = _dictKeyIndex(d, key, dictHashKey(d,key), existing)) == -1) return NULL; /* 给新的entry分配内存空间并且保存新的entry， * 在这里，会将新的元素放在hash表的表头 */ /* 如果字典这是正在rehash，那么会将entry添加到ht[1]中去；否则添加到ht[0] */ ht = dictIsRehashing(d) ? &amp;d-&gt;ht[1] : &amp;d-&gt;ht[0]; entry = zmalloc(sizeof(*entry)); entry-&gt;next = ht-&gt;table[index]; ht-&gt;table[index] = entry; ht-&gt;used++;/* 更新hash表中used属性的值 */ /* 设置entry的key */ dictSetKey(d, entry, key); return entry;&#125; PSUBSCRIBE 订阅模式（多个频道） 实现（源码）数据结构 和 redisServer.pubsub_channels 属性类似， redisServer.pubsub_patterns 属性用于保存所有被订阅的模式，和 pubsub_channels 不同的是， pubsub_patterns 是一个链表(而不是字典)： 123456struct redisServer &#123; // ...... list *pubsub_patterns; // A list of pubsub_patterns // ...... &#125; pubsubSubscribePattern 是 PSUBSCRIBE 的底层实现，它将客户端和所订阅的模式添加到redisServer.pubsub_patterns 当中： 123456789101112131415161718192021222324252627// 订阅指定模式 // 订阅成功返回 1 ，如果已经订阅过，返回 0 int pubsubSubscribePattern(redisClient *c, robj *pattern) &#123; int retval = 0; // 向 c-&gt;pubsub_patterns 中查找指定 pattern // 如果返回值为 NULL ，说明这个 pattern 还没被这个客户端订阅过 if (listSearchKey(c-&gt;pubsub_patterns,pattern) == NULL) &#123; retval = 1; // 添加 pattern 到客户端 pubsub_patterns listAddNodeTail(c-&gt;pubsub_patterns,pattern); incrRefCount(pattern); // 将 pattern 添加到服务器 pubsubPattern *pat; pat = zmalloc(sizeof(*pat)); pat-&gt;pattern = getDecodedObject(pattern); pat-&gt;client = c; listAddNodeTail(server.pubsub_patterns,pat); &#125; /* Notify the client */ addReply(c,shared.mbulkhdr[3]); addReply(c,shared.psubscribebulk); // 返回被订阅的模式 addReplyBulk(c,pattern); // 返回客户端当前已订阅的频道和模式数量的总和 addReplyLongLong(c,dictSize(c-&gt;pubsub_channels)+listLength(c-&gt;pubsub_patterns)); return retval; &#125; 这个的话如果每次添加都要去匹配每一个channel然后加client的话就太累了，这个东西也失去了意义，本来就是为了模式匹配的，这样一个个加，有点繁琐了。为了能让这玩意儿起作用，在publish中会在这里也遍历一次，在publish相应的执行函数中进行channel的对比，匹配上了就发。 UNSUBSCRIBE 不订阅 这个就比较随意啦，就不细讲。 TIPS个人一些理解上卡的关键点： 1.在没有一个channel的情况下是通过怎样的方式创建channel的呢？ 这个要结合源代码来看，没有channel的时候，其实也就是这个channel被首次订阅的时候，这个时候会调用dictAdd，而且是加在服务端serer.pubsub上的，细节可以看上面的源码，。 2.如果自己没订阅的话别人订阅了，那在pubsub里面有其他人订阅了了岂不是自己就订阅不了了？ 这个是我自己眼角膜不要了，我没看清楚的是在订阅相关的函数中第一个if条件中的pubsub是c-&gt;pubsub_channels，也就是说是客户端的一个字典，客户端的字典只是存了自己订阅的，里面的值啥都没有的。而下面的de的判断是server.pubsub，也就是远程的，那里面的list就会保存所有订阅了相应channel的客户端了。 3.为什么有ht[0]，ht[1]，没有2和3或4吗？ 通过搜索资料发现，dicth哈希字典里面自带了两个哈希表，0和1，这个人家里面本来就有，没得杠。dictht0是直接存储哈希表的地方， dictht1在rehash中用到。里面的一些详细问题暂时还没有参透，日后再说。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/tags/Redis/"},{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"IOTA-介绍","slug":"IOTA-介绍","date":"2019-11-14T10:21:54.000Z","updated":"2019-12-09T08:57:20.440Z","comments":true,"path":"2019/11/14/IOTA-介绍/","link":"","permalink":"http://yoursite.com/2019/11/14/IOTA-%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"引言本文参考了https://www.jianshu.com/p/45c72f6cb417https://www.iotachina.com/what-is-iotaIOTA 交易，确认和共识 简介 IOTA是为物联网（IoT）而设计的一个革命性的新型交易结算和数据转移层。它基于新型的分布式账本——Tangle（缠结）。Tangle能够克服现有区块链设计中的低效性，并为去中心化P2P系统共识的达成创造了一种新方法。通过IOTA进行转账不需要支付手续费，这是首例。这也就意味着，无论是多小额的支付都能通过IOTA完成。 IOTA的Tangle和区块链有什么不同？最小单位 区块链的最小单位是区块（可能包含多个交易） IOTA的最小单位是一次交易 架构他们是两个完全独立的架构，但是却建立在同一种规则之上。 IOTA共识机制创新 区块链共识是通过一个非常严格的机制完成的，区块链中添加下一个区块需要多方进行竞争，并获取区块奖励或交易手续费。正因如此，共识和交易生成是分离开的，并且由网络的一小部分人来完成，通常会设置较高门槛（就像比特币一样），这样会导致进一步的中心化。 在IOTA系统中，网络中的每位参与者都能进行交易并且积极参与共识。更具体点说，你直接定位了两笔交易（主交易和分支交易），且间接在子tangle中定位其它交易。通过这种方式，验证就能同步进行，网络能够保持完全去中心化，不需要矿工传递信任，也不需要支付交易手续费。 关于共识可以参考此篇文章IOTA 交易，确认和共识 手续费 基于比特币的交易需要支付矿工手续费，这里的矿工就是建立区块的节点。在未来小微支付广泛存在的物联网场景中，这种交易方式并不适用，因为这个手续费会大概率超过微小交易本身的价值，这种情况是非常不合理的。 同时，由于矿工的存在，使得比特币系统不可避免地拥有了节点二元性的特点 节点二元性：一类节点是参与交易的，而一类节点是参与确认交易的。这种二元性将会造成资源分配问题和公平性问题。 解决 ： 在IOTA中，每一笔新交易发生之前，该笔交易的节点首先要选择之前两个旧交易进行验证。验证通过后，该交易和被验证的两笔交易绑定。也就是说，要在IOTA网络上发行交易，就要对之前的交易进行验证。参与交易的每个节点都要承担一些矿工的义务，对整个网络的交易真实性负责。 这种记账的方式，不需要矿工，也不需要大量节点验证，这就节省了手续费和算力资源。有效地消除了手续费和网络二元性的问题，更加适用于大量节点之间小额交易的物联网场景。 数据结构 IOTA的和其他代币最根本的区别是底层数据结构的不同。其他代币大多是用区块链存储交易数据，而IOTA则是采用了缠结Tangle作为其底层的数据结构。 Tangle Tangle是一种存储交易数据的有向无环图（Directed Acyclic Graph, DAG），其基本结构如图所示。 交易过程选择旧交易一个节点在发行一个新的交易之前，首先要选择已经发生过的两个交易进行验证。关于选择哪两个交易，是IOTA技术的关键，最简单的策略是随机选择，并且要在还未被验证过的交易中进行选择。 （关键技术，还要深入） 验证旧交易选择好旧交易后，节点会对它们进行验证。要检查交易的签名是否正确，生成该交易的工作量大小，以及是否和与之直接或间接相连的交易有冲突。如果有冲突，则重新选择旧交易；如果没有冲突，则验证通过。 绑定旧交易验证通过后，节点将新生成的交易与已被验证的交易进行绑定。绑定过程需要做一点PoW计算，类似于比特币中的矿工，需要找到一个随机数满足如下条件：该随机数和被验证交易中的某个数值连接成新的字符串，该字符串对应的哈希值应满足某个固定格式。 （待补充，然后呢，需要广播吗》） （待补充）每次交易干了啥数据结构 IOTA的和其他代币最根本的区别是底层数据结构的不同。其他代币大多是用区块链存储交易数据，而IOTA则是采用了缠结Tangle作为其底层的数据结构。 Tangle Tangle是一种存储交易数据的有向无环图（Directed Acyclic Graph, DAG），其基本结构如图所示。 风险交易冲突 IOTA通过交易权重解决这个问题。 每个交易在生成时，都会附带两个权重值。 自有权重，为3的指数，固定不变； 累计权重，是其后续绑定交易自有权重的累加，随着交易的增多而变大。 （待补充）权重怎么算，权重怎么起作用 pow共识机制 交易在被验证的时候，两个权重值是重要参考指标。累计权重越大的交易，意味着其可信度越高。在交易冲突发生的时候，会比较两个交易的累计权重，并舍弃那个累计权重较小的交易及其分支，后续如果遇到合适的时机会会再加上。","categories":[{"name":"IOTA","slug":"IOTA","permalink":"http://yoursite.com/categories/IOTA/"}],"tags":[{"name":"IOTA","slug":"IOTA","permalink":"http://yoursite.com/tags/IOTA/"},{"name":"区块链","slug":"区块链","permalink":"http://yoursite.com/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/"},{"name":"论文","slug":"论文","permalink":"http://yoursite.com/tags/%E8%AE%BA%E6%96%87/"},{"name":"分布式","slug":"分布式","permalink":"http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"Redis-常用命令","slug":"Redis-常用命令","date":"2019-11-14T10:21:54.000Z","updated":"2019-11-16T08:24:53.428Z","comments":true,"path":"2019/11/14/Redis-常用命令/","link":"","permalink":"http://yoursite.com/2019/11/14/Redis-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"引言参考 https://blog.csdn.net/weixx3/article/details/92188775暂未附上声明 #","categories":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://yoursite.com/tags/Redis/"},{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"命令","slug":"命令","permalink":"http://yoursite.com/tags/%E5%91%BD%E4%BB%A4/"}]},{"title":"java-拆箱装箱","slug":"java-拆箱装箱","date":"2019-11-09T10:21:54.000Z","updated":"2019-11-17T12:55:42.247Z","comments":true,"path":"2019/11/09/java-拆箱装箱/","link":"","permalink":"http://yoursite.com/2019/11/09/java-%E6%8B%86%E7%AE%B1%E8%A3%85%E7%AE%B1/","excerpt":"","text":"前言本文转载于http://www.cnblogs.com/dolphin0520/p/3780005.html并根据自己的理解方式做了表达上的修改 概念Java SE5之前，如果要生成一个数值为10的Integer对象，必须这样进行： 1Integer i = new Integer(10); 而在从Java SE5开始就提供了自动装箱的特性，如果要生成一个数值为10的Integer对象，只需要这样就可以了： 1Integer i = 10; 这个过程中会自动根据数值创建对应的 Integer对象，这就是装箱。 而拆箱就是将包装器类型的转化为基本数据类型的一个过程 12Integer i = 10; //装箱int n = i; //拆箱 实现原理Integer为例： 66通过javap -c 对.java文件进行反编译得到.class文件得到如下结果 在装箱的时候自动调用的是Integer的valueOf(int)方法 在拆箱的时候自动调用的是Integer的intValue方法 其他的数据类型也都是按照相似的方式拆箱装箱的 源码解析","categories":[{"name":"JAVA基础","slug":"JAVA基础","permalink":"http://yoursite.com/categories/JAVA%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://yoursite.com/tags/JAVA/"},{"name":"数据类型","slug":"数据类型","permalink":"http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"}]},{"title":"leetcode-最大回文子串","slug":"leetcode-最大回文子串","date":"2019-11-09T08:07:50.000Z","updated":"2019-11-09T08:58:45.629Z","comments":true,"path":"2019/11/09/leetcode-最大回文子串/","link":"","permalink":"http://yoursite.com/2019/11/09/leetcode-%E6%9C%80%E5%A4%A7%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2/","excerpt":"","text":"暴力法不多做详解 1.中心扩展法此方法主要思想:通过查找以字符串中以某个字符为中心的回文子串是有多长，来得到每个回文子串的大小。对于这个子串，我们就从中心出发，向两边扩展，如果扩展后还是回文串，那么继续扩展，直到不是回文串，我们就可以将子串长度记录下来了。对于向两边扩展，我们可以通过一个下标来表示（也可以用指针），p1和p2。 现在有个问题，aabbaa和aabaa都是回文串，所以在打代码的时候就要稍稍做个处理。 两种情况 回文子串是奇数个，那么中心点就是一个字符，所以初始状态，p1和p2是指向同一个字符的。 回文子串是偶数个，那么中心就是两个字符，所以初始状态，p1和p2是指向两个相同字符的。 对于两种情况的处理打代码稍稍注意下就好了，问题不大。（这个方法暂无代码……） 2.动态规划主要思想：对于i到j是否是回文子串，我们只需要判断两个问题： i位置和j位置两个字符是否相同 如果相同了就判断i+1和j-1是否是个回文窜 有了这两点就没啥问题了 公式如下： 1dp[i][j] = dp[i+1][j-1] 这里的dp[i][j]存放的是boolean类型的，下面的dp存的是回文串长度 因为i一定会比j小，所以在二维数组上的操作要多多注意 一段比较原始的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public String longestPalindrome(String s) &#123; if (s.length() &lt;=1)&#123; return s; &#125; int len = s.length(); int dp[][] = new int[len][len]; //初始化dp数组，主要是a和aa这种先准备好 //dp数组每个格子存放当前i到j的回文子串长度 for (int i = 0;i &lt; len;i++)&#123; dp[i][i] = 1; //i到i（单个字符）就是个回文串 if (i != len-1)&#123; //aa也是个回文串 if (s.charAt(i) == s.charAt(i+1))&#123; dp[i][i+1] = 2; &#125; &#125; &#125; //这个循环和是纵列在外，横行在内 for (int i = 2; i &lt; len; i ++)&#123; //这里是j到i for (int j = 0;j &lt; i-1;j++)&#123; if (s.charAt(j) == s.charAt(i))&#123; if (dp[j+1][i-1] == 0)&#123; dp[j][i] = dp[j+1][i-1]; &#125;else &#123; dp[j][i] = dp[j+1][i-1] +2 ; &#125; &#125; &#125; &#125; //把最大子串给截出来 int left = 0; int right = 0; int maxlen = 0; for (int i =0;i&lt; len;i++)&#123; for (int j = i;j &lt; len;j++)&#123; if (dp[i][j] &gt; maxlen)&#123; maxlen = dp[i][j]; left = i; right = j; &#125; &#125; &#125; return s.substring(left,right+1); &#125; 3.Manacher算法（待更）","categories":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/categories/leetcode/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yoursite.com/tags/leetcode/"},{"name":"动态规划","slug":"动态规划","permalink":"http://yoursite.com/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"}]},{"title":"Linux下权限的修改设置","slug":"linux-permission","date":"2019-11-08T08:46:26.000Z","updated":"2019-12-09T02:40:14.147Z","comments":true,"path":"2019/11/08/linux-permission/","link":"","permalink":"http://yoursite.com/2019/11/08/linux-permission/","excerpt":"","text":"修改文件权限1$ chmod -R 777 files 1.先来讲讲数字777代表的是三个级别的身份owner/group/others 对于每个级别都有三个不同的权限 r 读权限read 4，100 w 写权限write 2，010 x 操作权限execute 1， 001 如果rwx都可以，就对三个数进行相加，等于7。这个就相当于3bit的位来表示单个级别身份的权限，某个位上的1表示有这个位代表的权限，0表示没有 2.接着讲讲 R对于R的话其实表示：对目前目录下的所有文件与子目录进行相同的权限变更(即以递回的方式逐个变更) 3.其他当然除了 1chmod -R XXX file.txt 也有其他的方式，主要是依据owner/group/others三个用户来的。 栗子：设置文件拥有者权限为可写，组合为可读，其他用户删去可执行权限 1chmod u+w,g+r,o-x files.txt own对应 u group对应 g other对应 o 所有对应 a 此处自己只是列举了自己常用的，部分深入的细节没有完全解释清楚，网上也有大片的参考。 详细的可以到这里看看","categories":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/categories/Linux/"}],"tags":[{"name":"命令","slug":"命令","permalink":"http://yoursite.com/tags/%E5%91%BD%E4%BB%A4/"},{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"初来乍到","slug":"myblog-creation","date":"2019-11-08T05:54:13.000Z","updated":"2019-11-17T05:35:04.491Z","comments":false,"path":"2019/11/08/myblog-creation/","link":"","permalink":"http://yoursite.com/2019/11/08/myblog-creation/","excerpt":"","text":"第一次建站，若有问题欢迎大家指正。 有问题欢迎大家发送邮件和我探讨交流172544714@qq.com","categories":[{"name":"Helloworld","slug":"Helloworld","permalink":"http://yoursite.com/categories/Helloworld/"}],"tags":[{"name":"HEXO","slug":"HEXO","permalink":"http://yoursite.com/tags/HEXO/"}]}]}